{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scripts.simulation_imports import *\n",
    "\n",
    "from openai import OpenAI\n",
    "from ast import literal_eval\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path.home() / Path(os.environ.get(\"RSYS_DATA\", \"rsys_data/rsys_2025\"))\n",
    "gen_slates_dir = DATA_PATH / \"gen_slates\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "feather_file_path_wp= gen_slates_dir / \"wp_llm_slates.feather\"\n",
    "df=pd.read_feather(feather_file_path_wp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path.home() / Path(os.environ.get(\"DATA_PATH\"))\n",
    "dataset_interaction_path = DATA_PATH / Path(\"MINDlarge_train/test_50.feather\")\n",
    "interaction_data = pd.read_feather(dataset_interaction_path)\n",
    "dataset_path =DATA_PATH / Path(\"MINDlarge_train/test_50.feather\")\n",
    "category_data = pd.read_feather(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path.home() / Path(os.environ.get(\"DATA_PATH\"))\n",
    "news_df = pd.read_feather(\n",
    "            base_path / Path(\"MINDlarge_train/news_glove_embed_50.feather\")\n",
    "        )\n",
    "embedding_dict = dict(zip(news_df[\"itemId\"], news_df[\"embedding\"]))\n",
    "embedding_lookup = {tuple(item_embedding): item_id for item_id, item_embedding in embedding_dict.items() if item_embedding is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = news_df['category'].unique()\n",
    "news_df[\"num_category\"] = news_df[\"category\"].factorize()[0]\n",
    "article_category = news_df.set_index(\"itemId\")[\"num_category\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def click_history_diversity(row) :\n",
    "        items_hist = row[\"click_history\"]\n",
    "        categories = [\n",
    "            article_category.get(article_id, 0) for article_id in items_hist\n",
    "        ]\n",
    "        category_counts = [categories.count(i) for i in range(0, 18)]\n",
    "        total_count = sum(category_counts)\n",
    "        probs = [count / total_count for count in category_counts]\n",
    "        entropy = 0\n",
    "        for prob in probs:\n",
    "            if prob > 0:\n",
    "                entropy-= prob * math.log2(prob)\n",
    "        # score = sum(1 for x in count_categories if x > 0) / 18\n",
    "        return entropy\n",
    "\n",
    "def entropy_based_diversity(row):\n",
    "\n",
    "  # Normalize the counts to get probabilities\n",
    "    items_hist = row[\"click_history\"]\n",
    "    categories = [\n",
    "        article_category.get(article_id, 0) for article_id in items_hist\n",
    "    ]\n",
    "    category_counts = [categories.count(i) for i in range(0, 18)]\n",
    "    probs = category_counts / np.sum(category_counts)\n",
    "\n",
    "    # Handle zero probabilities (avoid log of zero)\n",
    "    probs = np.where(probs > 0, probs, 1e-10)\n",
    "\n",
    "    # Calculate entropy\n",
    "    entropy = -np.sum(probs * np.log2(probs))\n",
    "\n",
    "    # Normalize entropy (optional, comment out if not needed)\n",
    "    diversity_score = entropy / np.log2(len(category_counts))\n",
    "\n",
    "    return diversity_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wolpertinger+LLM Slates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve item IDs for candidate_docs\n",
    "candidate_ids = [[embedding_lookup.get(tuple(embedding), \"Not Found\") for embedding in candidate_list] \n",
    "                 for candidate_list in df[\"candidate_docs\"]]\n",
    "\n",
    "# Retrieve item IDs for slate_docs_feature\n",
    "slate_item_ids = [[embedding_lookup.get(tuple(embedding), \"Not Found\") for embedding in slate_list] \n",
    "                  for slate_list in df[\"slate_docs_feature\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_ids_and_titles(item_ids, news_df):\n",
    "    # Create a dictionary of itemId -> title for faster lookup\n",
    "    item_to_title = dict(zip(news_df[\"itemId\"], news_df[\"title\"]))\n",
    "    \n",
    "    # Retrieve the titles for each item_id\n",
    "    item_titles = [(item_id, item_to_title.get(item_id, \"Title not found\")) for item_id in item_ids]\n",
    "    \n",
    "    return item_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initial_user_state</th>\n",
       "      <th>candidate_docs</th>\n",
       "      <th>slate_docs</th>\n",
       "      <th>slate_docs_feature</th>\n",
       "      <th>llm_slate</th>\n",
       "      <th>original_click</th>\n",
       "      <th>hit</th>\n",
       "      <th>initial_user_state_tuple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.1973009705543518, 0.13024283945560455, -0.0...</td>\n",
       "      <td>[[-0.04699699580669403, -0.1554999053478241, 0...</td>\n",
       "      <td>[7, 38, 34, 50, 25, 18, 29, 12, 8, 36]</td>\n",
       "      <td>[[0.16044361889362335, 0.02018088661134243, -0...</td>\n",
       "      <td>[N94421, N114252, N96729, N43628, N91392, N725...</td>\n",
       "      <td>N53474</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1973009705543518, 0.13024283945560455, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1973009705543518, 0.13024283945560455, -0.0...</td>\n",
       "      <td>[[-0.04699699580669403, -0.1554999053478241, 0...</td>\n",
       "      <td>[7, 50, 38, 25, 34, 56, 47, 8, 54, 51]</td>\n",
       "      <td>[[0.16044361889362335, 0.02018088661134243, -0...</td>\n",
       "      <td>[N94421, N43628, N114252, N93087, N108178, N72...</td>\n",
       "      <td>N94421</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.1973009705543518, 0.13024283945560455, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.1973009705543518, 0.13024283945560455, -0.0...</td>\n",
       "      <td>[[-0.04699699580669403, -0.1554999053478241, 0...</td>\n",
       "      <td>[47, 48, 34, 44, 21, 15, 40, 1, 0, 54]</td>\n",
       "      <td>[[0.4234131872653961, 0.16742219030857086, 0.2...</td>\n",
       "      <td>[N94421, N114252, N35564, N89473, N78654, N436...</td>\n",
       "      <td>N72609</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1973009705543518, 0.13024283945560455, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.1973009705543518, 0.13024283945560455, -0.0...</td>\n",
       "      <td>[[-0.04699699580669403, -0.1554999053478241, 0...</td>\n",
       "      <td>[47, 48, 34, 44, 21, 15, 40, 1, 0, 54]</td>\n",
       "      <td>[[0.4234131872653961, 0.16742219030857086, 0.2...</td>\n",
       "      <td>[]</td>\n",
       "      <td>N108178</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.1973009705543518, 0.13024283945560455, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.12371931970119476, 0.22699563205242157, -0....</td>\n",
       "      <td>[[0.12557996809482574, 0.09453339874744415, -0...</td>\n",
       "      <td>[35, 53, 57, 3, 17, 29, 48, 20, 49, 55]</td>\n",
       "      <td>[[0.06847824156284332, 0.1842382550239563, -0....</td>\n",
       "      <td>[]</td>\n",
       "      <td>N123784</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.12371931970119476, 0.22699563205242157, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>[0.2901885509490967, 0.09240760654211044, -0.0...</td>\n",
       "      <td>[[0.44853997230529785, 0.09333121031522751, 0....</td>\n",
       "      <td>[34, 51, 10, 27, 12, 50, 4, 48, 21, 9]</td>\n",
       "      <td>[[0.2181687355041504, 0.2414197027683258, -0.0...</td>\n",
       "      <td>[N73618, N19966, N48953, N39403, N112953, N515...</td>\n",
       "      <td>N41710</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.2901885509490967, 0.09240760654211044, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>[0.2759395241737366, 0.2625528872013092, -0.12...</td>\n",
       "      <td>[[0.1271628737449646, 0.11576124280691147, -0....</td>\n",
       "      <td>[15, 2, 12, 31, 42, 45, 52, 32, 48, 3]</td>\n",
       "      <td>[[0.30415692925453186, 0.4279513955116272, -0....</td>\n",
       "      <td>[N44884, N93669, N22987, N55217, N37759, N4284...</td>\n",
       "      <td>N62595</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.2759395241737366, 0.2625528872013092, -0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>[0.2759395241737366, 0.2625528872013092, -0.12...</td>\n",
       "      <td>[[0.1271628737449646, 0.11576124280691147, -0....</td>\n",
       "      <td>[52, 15, 50, 32, 29, 9, 3, 41, 31, 42]</td>\n",
       "      <td>[[0.048676200211048126, 0.18606841564178467, 0...</td>\n",
       "      <td>[N37759, N4284, N118589, N106197, N35063, N229...</td>\n",
       "      <td>N118589</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.2759395241737366, 0.2625528872013092, -0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>[0.2759395241737366, 0.2625528872013092, -0.12...</td>\n",
       "      <td>[[0.1271628737449646, 0.11576124280691147, -0....</td>\n",
       "      <td>[12, 31, 3, 2, 42, 45, 15, 52, 48, 9]</td>\n",
       "      <td>[[0.4208182990550995, 0.01135310996323824, -0....</td>\n",
       "      <td>[N37759, N70696, N54882, N44884, N22987, N4284...</td>\n",
       "      <td>N43186</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.2759395241737366, 0.2625528872013092, -0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>[0.2759395241737366, 0.2625528872013092, -0.12...</td>\n",
       "      <td>[[0.1271628737449646, 0.11576124280691147, -0....</td>\n",
       "      <td>[48, 15, 32, 47, 52, 12, 0, 29, 34, 56]</td>\n",
       "      <td>[[0.17637601494789124, 0.044959042221307755, 0...</td>\n",
       "      <td>[N37759, N23143, N55217, N124106, N64392, N429...</td>\n",
       "      <td>N32209</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.2759395241737366, 0.2625528872013092, -0.12...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>325 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    initial_user_state  \\\n",
       "0    [0.1973009705543518, 0.13024283945560455, -0.0...   \n",
       "1    [0.1973009705543518, 0.13024283945560455, -0.0...   \n",
       "2    [0.1973009705543518, 0.13024283945560455, -0.0...   \n",
       "3    [0.1973009705543518, 0.13024283945560455, -0.0...   \n",
       "4    [0.12371931970119476, 0.22699563205242157, -0....   \n",
       "..                                                 ...   \n",
       "320  [0.2901885509490967, 0.09240760654211044, -0.0...   \n",
       "321  [0.2759395241737366, 0.2625528872013092, -0.12...   \n",
       "322  [0.2759395241737366, 0.2625528872013092, -0.12...   \n",
       "323  [0.2759395241737366, 0.2625528872013092, -0.12...   \n",
       "324  [0.2759395241737366, 0.2625528872013092, -0.12...   \n",
       "\n",
       "                                        candidate_docs  \\\n",
       "0    [[-0.04699699580669403, -0.1554999053478241, 0...   \n",
       "1    [[-0.04699699580669403, -0.1554999053478241, 0...   \n",
       "2    [[-0.04699699580669403, -0.1554999053478241, 0...   \n",
       "3    [[-0.04699699580669403, -0.1554999053478241, 0...   \n",
       "4    [[0.12557996809482574, 0.09453339874744415, -0...   \n",
       "..                                                 ...   \n",
       "320  [[0.44853997230529785, 0.09333121031522751, 0....   \n",
       "321  [[0.1271628737449646, 0.11576124280691147, -0....   \n",
       "322  [[0.1271628737449646, 0.11576124280691147, -0....   \n",
       "323  [[0.1271628737449646, 0.11576124280691147, -0....   \n",
       "324  [[0.1271628737449646, 0.11576124280691147, -0....   \n",
       "\n",
       "                                  slate_docs  \\\n",
       "0     [7, 38, 34, 50, 25, 18, 29, 12, 8, 36]   \n",
       "1     [7, 50, 38, 25, 34, 56, 47, 8, 54, 51]   \n",
       "2     [47, 48, 34, 44, 21, 15, 40, 1, 0, 54]   \n",
       "3     [47, 48, 34, 44, 21, 15, 40, 1, 0, 54]   \n",
       "4    [35, 53, 57, 3, 17, 29, 48, 20, 49, 55]   \n",
       "..                                       ...   \n",
       "320   [34, 51, 10, 27, 12, 50, 4, 48, 21, 9]   \n",
       "321   [15, 2, 12, 31, 42, 45, 52, 32, 48, 3]   \n",
       "322   [52, 15, 50, 32, 29, 9, 3, 41, 31, 42]   \n",
       "323    [12, 31, 3, 2, 42, 45, 15, 52, 48, 9]   \n",
       "324  [48, 15, 32, 47, 52, 12, 0, 29, 34, 56]   \n",
       "\n",
       "                                    slate_docs_feature  \\\n",
       "0    [[0.16044361889362335, 0.02018088661134243, -0...   \n",
       "1    [[0.16044361889362335, 0.02018088661134243, -0...   \n",
       "2    [[0.4234131872653961, 0.16742219030857086, 0.2...   \n",
       "3    [[0.4234131872653961, 0.16742219030857086, 0.2...   \n",
       "4    [[0.06847824156284332, 0.1842382550239563, -0....   \n",
       "..                                                 ...   \n",
       "320  [[0.2181687355041504, 0.2414197027683258, -0.0...   \n",
       "321  [[0.30415692925453186, 0.4279513955116272, -0....   \n",
       "322  [[0.048676200211048126, 0.18606841564178467, 0...   \n",
       "323  [[0.4208182990550995, 0.01135310996323824, -0....   \n",
       "324  [[0.17637601494789124, 0.044959042221307755, 0...   \n",
       "\n",
       "                                             llm_slate original_click  hit  \\\n",
       "0    [N94421, N114252, N96729, N43628, N91392, N725...         N53474    0   \n",
       "1    [N94421, N43628, N114252, N93087, N108178, N72...         N94421    1   \n",
       "2    [N94421, N114252, N35564, N89473, N78654, N436...         N72609    0   \n",
       "3                                                   []        N108178    0   \n",
       "4                                                   []        N123784    0   \n",
       "..                                                 ...            ...  ...   \n",
       "320  [N73618, N19966, N48953, N39403, N112953, N515...         N41710    0   \n",
       "321  [N44884, N93669, N22987, N55217, N37759, N4284...         N62595    1   \n",
       "322  [N37759, N4284, N118589, N106197, N35063, N229...        N118589    1   \n",
       "323  [N37759, N70696, N54882, N44884, N22987, N4284...         N43186    0   \n",
       "324  [N37759, N23143, N55217, N124106, N64392, N429...         N32209    0   \n",
       "\n",
       "                              initial_user_state_tuple  \n",
       "0    [0.1973009705543518, 0.13024283945560455, -0.0...  \n",
       "1    [0.1973009705543518, 0.13024283945560455, -0.0...  \n",
       "2    [0.1973009705543518, 0.13024283945560455, -0.0...  \n",
       "3    [0.1973009705543518, 0.13024283945560455, -0.0...  \n",
       "4    [0.12371931970119476, 0.22699563205242157, -0....  \n",
       "..                                                 ...  \n",
       "320  [0.2901885509490967, 0.09240760654211044, -0.0...  \n",
       "321  [0.2759395241737366, 0.2625528872013092, -0.12...  \n",
       "322  [0.2759395241737366, 0.2625528872013092, -0.12...  \n",
       "323  [0.2759395241737366, 0.2625528872013092, -0.12...  \n",
       "324  [0.2759395241737366, 0.2625528872013092, -0.12...  \n",
       "\n",
       "[325 rows x 8 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_data[\"observed_state\"] = category_data[\"observed_state\"].apply(lambda x: tuple(x) if x is not None else ())\n",
    "click_history_data = category_data[['observed_state', 'click_history']]\n",
    "click_history_data = click_history_data.drop_duplicates(subset=['observed_state'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['initial_user_state_tuple'] = df['initial_user_state'].apply(tuple)\n",
    "# Step 2: Merge with df based on the matching condition\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    click_history_data,\n",
    "    left_on='initial_user_state_tuple',\n",
    "    right_on='observed_state',\n",
    "    how='left'  # Use 'left' to keep all rows from df, or 'inner' for only matching rows\n",
    ")\n",
    "\n",
    "# Drop the extra 'observed_state' column if you don't need it\n",
    "df = df.drop(columns=['observed_state'])\n",
    "df['diversity_score']=df.apply(entropy_based_diversity,axis=1)\n",
    "q1 = df['diversity_score'].quantile(0.25)\n",
    "conditions = [\n",
    "    df['diversity_score'] == 0,  # Cold\n",
    "    df['diversity_score'] <= q1,  # Specialist\n",
    "    df['diversity_score'] > q1    # Generalist\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    'cold',\n",
    "    'specialist',\n",
    "    'generalist'\n",
    "]\n",
    "\n",
    "# Step 3: Use numpy.select to apply the conditions\n",
    "df['user_type'] = np.select(conditions, choices, default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  group_mean_hit\n",
      "0   (-0.0259791798889637, 0.5851805210113525, 0.00...        0.250000\n",
      "1   (0.049241334199905396, 0.23491184413433075, 0....        0.333333\n",
      "2   (0.06917192041873932, 0.22154483199119568, 0.0...        0.000000\n",
      "3   (0.0808219462633133, 0.280564546585083, -0.035...        0.142857\n",
      "4   (0.11326862126588821, 0.38108861446380615, -0....        0.142857\n",
      "..                                                ...             ...\n",
      "95  (0.3616601228713989, 0.1373804360628128, 0.021...        0.000000\n",
      "96  (0.3617928624153137, 0.11457429826259613, 0.01...        0.000000\n",
      "97  (0.36578845977783203, 0.042487733066082, 0.081...        0.500000\n",
      "98  (0.39353927969932556, 0.0698390007019043, -0.0...        0.000000\n",
      "99  (0.3967207372188568, 0.18588663637638092, -0.0...        0.000000\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.1825281385281385\n"
     ]
    }
   ],
   "source": [
    "df= df[df['llm_slate'].apply(lambda x: len(x) > 0)].copy()\n",
    "\n",
    "\n",
    "# Step 2: Group by initial_user_state and calculate the mean of 'hit' for each group\n",
    "grouped_means_rl_llm = df.groupby('initial_user_state_tuple')['hit'].mean().reset_index()\n",
    "grouped_means_rl_llm.rename(columns={'hit': 'group_mean_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_rl_llm['group_mean_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_rl_llm)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average for Specialists:\n",
      "0.12935064935064933\n",
      "\n",
      "Overall average for Generalists:\n",
      "0.20025396825396824\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Filter the DataFrame for specialists and generalists\n",
    "specialists_df = df[df['user_type'] == 'specialist'].copy()\n",
    "generalists_df = df[df['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of 'hit' for each group\n",
    "# For specialists\n",
    "grouped_means_specialists = specialists_df.groupby('initial_user_state_tuple')['hit'].mean().reset_index()\n",
    "grouped_means_specialists.rename(columns={'hit': 'group_mean_hit'}, inplace=True)\n",
    "\n",
    "# For generalists\n",
    "grouped_means_generalists = generalists_df.groupby('initial_user_state_tuple')['hit'].mean().reset_index()\n",
    "grouped_means_generalists.rename(columns={'hit': 'group_mean_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "# For specialists\n",
    "overall_mean_specialists = grouped_means_specialists['group_mean_hit'].mean()\n",
    "\n",
    "# For generalists\n",
    "overall_mean_generalists = grouped_means_generalists['group_mean_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "# print(\"Group-level averages for Specialists:\")\n",
    "# print(grouped_means_specialists)\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "# print(\"\\nGroup-level averages for Generalists:\")\n",
    "# print(grouped_means_generalists)\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rl_slates'] = [\n",
    "    [embedding_lookup.get(tuple(embedding), \"Not Found\") for embedding in slate_list]\n",
    "    for slate_list in df['slate_docs_feature']\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rl_hit'] = df.apply(lambda row: 1 if row['original_click'] in row['rl_slates'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  group_mean_rl_hit\n",
      "0   (-0.0259791798889637, 0.5851805210113525, 0.00...           0.000000\n",
      "1   (0.049241334199905396, 0.23491184413433075, 0....           0.000000\n",
      "2   (0.06917192041873932, 0.22154483199119568, 0.0...           0.000000\n",
      "3   (0.0808219462633133, 0.280564546585083, -0.035...           0.000000\n",
      "4   (0.11326862126588821, 0.38108861446380615, -0....           0.142857\n",
      "..                                                ...                ...\n",
      "95  (0.3616601228713989, 0.1373804360628128, 0.021...           0.000000\n",
      "96  (0.3617928624153137, 0.11457429826259613, 0.01...           0.000000\n",
      "97  (0.36578845977783203, 0.042487733066082, 0.081...           0.000000\n",
      "98  (0.39353927969932556, 0.0698390007019043, -0.0...           0.000000\n",
      "99  (0.3967207372188568, 0.18588663637638092, -0.0...           0.000000\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.047432900432900424\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 2: Group by initial_user_state and calculate the mean of 'hit' for each group\n",
    "grouped_means_rl = df.groupby('initial_user_state_tuple')['rl_hit'].mean().reset_index()\n",
    "grouped_means_rl.rename(columns={'rl_hit': 'group_mean_rl_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_rl['group_mean_rl_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_rl)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average for Specialists:\n",
      "0.022683982683982685\n",
      "\n",
      "Overall average for Generalists:\n",
      "0.055682539682539674\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Filter the DataFrame for specialists and generalists\n",
    "specialists_df = df[df['user_type'] == 'specialist'].copy()\n",
    "generalists_df = df[df['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of 'hit' for each group\n",
    "# For specialists\n",
    "grouped_means_specialists = specialists_df.groupby('initial_user_state_tuple')['rl_hit'].mean().reset_index()\n",
    "grouped_means_specialists.rename(columns={'rl_hit': 'group_mean_rl_hit'}, inplace=True)\n",
    "\n",
    "# For generalists\n",
    "grouped_means_generalists = generalists_df.groupby('initial_user_state_tuple')['rl_hit'].mean().reset_index()\n",
    "grouped_means_generalists.rename(columns={'rl_hit': 'group_mean_rl_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "# For specialists\n",
    "overall_mean_specialists = grouped_means_specialists['group_mean_rl_hit'].mean()\n",
    "\n",
    "# For generalists\n",
    "overall_mean_generalists = grouped_means_generalists['group_mean_rl_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "# print(\"Group-level averages for Specialists:\")\n",
    "# print(grouped_means_specialists)\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "# print(\"\\nGroup-level averages for Generalists:\")\n",
    "# print(grouped_means_generalists)\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "def hybrid_slate_optimization(row):\n",
    "    \"\"\"\n",
    "    Replaces the 3 least relevant items in the slate using a hybrid BM25 + cosine similarity approach.\n",
    "\n",
    "    Args:\n",
    "        row: A row from the DataFrame (passed via df.apply).\n",
    "\n",
    "    Returns:\n",
    "        Updated slate as a list of item IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve item IDs using the embedding lookup\n",
    "    slate_item_ids = [embedding_lookup.get(tuple(embedding), \"Not Found\") for embedding in row[\"slate_docs_feature\"]]\n",
    "    candidate_item_ids = [embedding_lookup.get(tuple(embedding), \"Not Found\") for embedding in row[\"candidate_docs\"]]\n",
    "\n",
    "    # Get titles for slate and candidate items\n",
    "    slate_titles = [title for _, title in get_item_ids_and_titles(slate_item_ids, news_df)]\n",
    "    candidate_titles = [title for _, title in get_item_ids_and_titles(candidate_item_ids, news_df)]\n",
    "    \n",
    "\n",
    "    # Tokenize titles for BM25\n",
    "    slate_tokens = [text.split() for text in slate_titles]\n",
    "    candidate_tokens = [text.split() for text in candidate_titles]\n",
    "    \n",
    "    bm25 = BM25Okapi(candidate_tokens)\n",
    "    bm25_scores = np.array([bm25.get_scores(tokens) for tokens in slate_tokens])  # (N, M)\n",
    "\n",
    "    # Compute Cosine Similarity scores\n",
    "    candidate_docs_matrix = np.array(row[\"candidate_docs\"])  # Convert to 2D numpy array\n",
    "    candidate_docs_matrix = np.vstack(row[\"candidate_docs\"])\n",
    "    slate_docs_feature_matrix = np.array(row[\"slate_docs_feature\"])  # Convert to 2D numpy array\n",
    "    slate_docs_feature_matrix = np.vstack(row[\"slate_docs_feature\"])\n",
    "\n",
    "    similarity_matrix = cosine_similarity(slate_docs_feature_matrix,candidate_docs_matrix)  # (M, N)\n",
    "    \n",
    "   \n",
    "   \n",
    "    # Normalize and Combine Scores\n",
    "    lambda_weight = 1.0  # Adjust balance between BM25 and cosine similarity\n",
    "    bm25_norm = (bm25_scores - bm25_scores.min()) / (bm25_scores.max() - bm25_scores.min() + 1e-6)\n",
    "    # bm25_norm = bm25_norm.T \n",
    "    cosine_norm = (similarity_matrix - similarity_matrix.min()) / (similarity_matrix.max() - similarity_matrix.min() + 1e-6)\n",
    "  \n",
    "    final_scores = lambda_weight * bm25_norm + (1 - lambda_weight) * cosine_norm  # (N, M)\n",
    "    \n",
    "\n",
    "    # Identify 3 least relevant slate items\n",
    "    avg_slate_relevance = final_scores.mean(axis=1)  # Average score per slate item\n",
    "    least_relevant_indices = np.argsort(avg_slate_relevance)[:9]  # Indices of 3 least relevant slate items\n",
    "\n",
    "    # Select 3 best candidates\n",
    "    best_candidate_indices = np.argsort(final_scores.max(axis=0))[-9:]  # Indices of top 3 candidates\n",
    "\n",
    "    # Replace the least relevant slate items with best candidates\n",
    "    updated_slate_item_ids = slate_item_ids[:]\n",
    "    for slate_idx, candidate_idx in zip(least_relevant_indices, best_candidate_indices):\n",
    "        updated_slate_item_ids[slate_idx] = candidate_item_ids[candidate_idx]  # Replace with best candidate ID\n",
    "    \n",
    "\n",
    "    return updated_slate_item_ids\n",
    "\n",
    "# Apply function to DataFrame\n",
    "\n",
    "df[\"slate_reranked\"] = df.apply(hybrid_slate_optimization, axis=1)\n",
    "\n",
    "\n",
    "# # Save the updated DataFrame\n",
    "# df.to_csv(\"updated_slate_data.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['reranked_hit'] = df.apply(lambda row: 1 if row['original_click'] in row['slate_reranked'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  group_mean_reranked_hit\n",
      "0   (-0.0259791798889637, 0.5851805210113525, 0.00...                 0.000000\n",
      "1   (0.049241334199905396, 0.23491184413433075, 0....                 0.000000\n",
      "2   (0.06917192041873932, 0.22154483199119568, 0.0...                 0.000000\n",
      "3   (0.0808219462633133, 0.280564546585083, -0.035...                 0.000000\n",
      "4   (0.11326862126588821, 0.38108861446380615, -0....                 0.142857\n",
      "..                                                ...                      ...\n",
      "95  (0.3616601228713989, 0.1373804360628128, 0.021...                 0.000000\n",
      "96  (0.3617928624153137, 0.11457429826259613, 0.01...                 0.000000\n",
      "97  (0.36578845977783203, 0.042487733066082, 0.081...                 0.000000\n",
      "98  (0.39353927969932556, 0.0698390007019043, -0.0...                 0.000000\n",
      "99  (0.3967207372188568, 0.18588663637638092, -0.0...                 0.000000\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.0440995670995671\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 2: Group by initial_user_state and calculate the mean of 'hit' for each group\n",
    "grouped_means_bm25 = df.groupby('initial_user_state_tuple')['reranked_hit'].mean().reset_index()\n",
    "grouped_means_bm25.rename(columns={'reranked_hit': 'group_mean_reranked_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_bm25['group_mean_reranked_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_bm25)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall average for Specialists:\n",
      "0.00935064935064935\n",
      "\n",
      "Overall average for Generalists:\n",
      "0.055682539682539674\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Filter the DataFrame for specialists and generalists\n",
    "specialists_df = df[df['user_type'] == 'specialist'].copy()\n",
    "generalists_df = df[df['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of 'hit' for each group\n",
    "# For specialists\n",
    "grouped_means_specialists = specialists_df.groupby('initial_user_state_tuple')['reranked_hit'].mean().reset_index()\n",
    "grouped_means_specialists.rename(columns={'reranked_hit': 'group_mean_reranked_hit'}, inplace=True)\n",
    "\n",
    "# For generalists\n",
    "grouped_means_generalists = generalists_df.groupby('initial_user_state_tuple')['reranked_hit'].mean().reset_index()\n",
    "grouped_means_generalists.rename(columns={'reranked_hit': 'group_mean_reranked_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "# For specialists\n",
    "overall_mean_specialists = grouped_means_specialists['group_mean_reranked_hit'].mean()\n",
    "\n",
    "# For generalists\n",
    "overall_mean_generalists = grouped_means_generalists['group_mean_reranked_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "# print(\"Group-level averages for Specialists:\")\n",
    "# print(grouped_means_specialists)\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "# print(\"\\nGroup-level averages for Generalists:\")\n",
    "# print(grouped_means_generalists)\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average S-Recall for llm_slate:\n",
      "Category Level: 0.3851, Subcategory Level: 0.6452\n",
      "\n",
      "Average S-Recall for rl_slates:\n",
      "Category Level: 0.5696, Subcategory Level: 0.8658\n",
      "\n",
      "Average S-Recall for slate_reranked:\n",
      "Category Level: 0.5266, Subcategory Level: 0.7889\n",
      "\n",
      "Number of subcategories for each category:\n",
      "         category  subcategory_count\n",
      "0           autos                 25\n",
      "1   entertainment                 14\n",
      "2         finance                 33\n",
      "3    foodanddrink                 16\n",
      "4           games                  1\n",
      "5          health                 23\n",
      "6            kids                  6\n",
      "7       lifestyle                 53\n",
      "8      middleeast                  1\n",
      "9          movies                  7\n",
      "10          music                 11\n",
      "11           news                 38\n",
      "12   northamerica                  1\n",
      "13         sports                 34\n",
      "14         travel                 16\n",
      "15             tv                 10\n",
      "16          video                 15\n",
      "17        weather                  3\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary for quick lookup of category and subcategory\n",
    "item_to_category = dict(zip(news_df['itemId'], news_df['category']))\n",
    "item_to_subcategory = dict(zip(news_df['itemId'], news_df['subcategory']))\n",
    "\n",
    "# Calculate total unique categories and subcategories in the dataset\n",
    "total_categories = news_df['category'].nunique()\n",
    "total_subcategories = news_df['subcategory'].nunique()\n",
    "\n",
    "# Function to calculate diversity metrics for a given slate\n",
    "def calculate_diversity(slate, item_to_category, item_to_subcategory):\n",
    "    categories = set()\n",
    "    subcategories = set()\n",
    "    \n",
    "    for item in slate:\n",
    "        if item in item_to_category:\n",
    "            categories.add(item_to_category[item])\n",
    "        if item in item_to_subcategory:\n",
    "            subcategories.add(item_to_subcategory[item])\n",
    "    \n",
    "    return len(categories), len(subcategories)\n",
    "\n",
    "# Function to calculate S-Recall as a ratio\n",
    "def calculate_s_recall(df, column, item_to_category, item_to_subcategory, total_categories, total_subcategories):\n",
    "    results = []\n",
    "    \n",
    "    for slate in df[column]:\n",
    "        category_diversity, subcategory_diversity = calculate_diversity(slate, item_to_category, item_to_subcategory)\n",
    "        \n",
    "        # Calculate S-Recall as a ratio\n",
    "        s_recall_category = category_diversity / len(slate)\n",
    "        s_recall_subcategory = subcategory_diversity / len(slate)\n",
    "        \n",
    "        results.append((s_recall_category, s_recall_subcategory))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Calculate S-Recall for each slate column\n",
    "llm_s_recall = calculate_s_recall(df, 'llm_slate', item_to_category, item_to_subcategory, total_categories, total_subcategories)\n",
    "rl_s_recall = calculate_s_recall(df, 'rl_slates', item_to_category, item_to_subcategory, total_categories, total_subcategories)\n",
    "slate_reranked_recall = calculate_s_recall(df, 'slate_reranked', item_to_category, item_to_subcategory, total_categories, total_subcategories)\n",
    "\n",
    "# Calculate average S-Recall for each column\n",
    "def calculate_average_s_recall(s_recall_results):\n",
    "    avg_category = sum([x[0] for x in s_recall_results]) / len(s_recall_results)\n",
    "    avg_subcategory = sum([x[1] for x in s_recall_results]) / len(s_recall_results)\n",
    "    return avg_category, avg_subcategory\n",
    "\n",
    "llm_avg_category, llm_avg_subcategory = calculate_average_s_recall(llm_s_recall)\n",
    "rl_avg_category, rl_avg_subcategory = calculate_average_s_recall(rl_s_recall)\n",
    "slate_avg_category, slate_avg_subcategory = calculate_average_s_recall(slate_reranked_recall)\n",
    "\n",
    "# Print average S-Recall for each column\n",
    "print(\"Average S-Recall for llm_slate:\")\n",
    "print(f\"Category Level: {llm_avg_category:.4f}, Subcategory Level: {llm_avg_subcategory:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for rl_slates:\")\n",
    "print(f\"Category Level: {rl_avg_category:.4f}, Subcategory Level: {rl_avg_subcategory:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for slate_reranked:\")\n",
    "print(f\"Category Level: {slate_avg_category:.4f}, Subcategory Level: {slate_avg_subcategory:.4f}\")\n",
    "\n",
    "# Calculate number of subcategories for each category\n",
    "subcategory_count = news_df.groupby('category')['subcategory'].nunique().reset_index()\n",
    "subcategory_count.columns = ['category', 'subcategory_count']\n",
    "\n",
    "print(\"\\nNumber of subcategories for each category:\")\n",
    "print(subcategory_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average S-Recall for llm_slate:\n",
      "Category Level: 0.3851, Subcategory Level: 0.0700\n",
      "\n",
      "Average S-Recall for rl_slates:\n",
      "Category Level: 0.5696, Subcategory Level: 0.0598\n",
      "\n",
      "Average S-Recall for slate_reranked:\n",
      "Category Level: 0.5266, Subcategory Level: 0.0577\n",
      "\n",
      "Number of subcategories for each category:\n",
      "         category  subcategory_count\n",
      "0           autos                 25\n",
      "1   entertainment                 14\n",
      "2         finance                 33\n",
      "3    foodanddrink                 16\n",
      "4           games                  1\n",
      "5          health                 23\n",
      "6            kids                  6\n",
      "7       lifestyle                 53\n",
      "8      middleeast                  1\n",
      "9          movies                  7\n",
      "10          music                 11\n",
      "11           news                 38\n",
      "12   northamerica                  1\n",
      "13         sports                 34\n",
      "14         travel                 16\n",
      "15             tv                 10\n",
      "16          video                 15\n",
      "17        weather                  3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a dictionary to map categories to their subcategories\n",
    "category_to_subcategories = news_df.groupby('category')['subcategory'].unique().to_dict()\n",
    "\n",
    "# Function to calculate diversity metrics for a given slate\n",
    "def calculate_diversity(slate, item_to_category, item_to_subcategory):\n",
    "    categories = set()\n",
    "    subcategories = set()\n",
    "    \n",
    "    for item in slate:\n",
    "        if item in item_to_category:\n",
    "            categories.add(item_to_category[item])\n",
    "        if item in item_to_subcategory:\n",
    "            subcategories.add(item_to_subcategory[item])\n",
    "    \n",
    "    return categories, subcategories\n",
    "\n",
    "# Function to calculate S-Recall as a ratio\n",
    "def calculate_s_recall(df, column, item_to_category, item_to_subcategory, category_to_subcategories):\n",
    "    results = []\n",
    "    \n",
    "    for slate in df[column]:\n",
    "        categories_in_slate, subcategories_in_slate = calculate_diversity(slate, item_to_category, item_to_subcategory)\n",
    "        \n",
    "        # Calculate S-Recall at category level\n",
    "        s_recall_category = len(categories_in_slate) / len(slate)\n",
    "        \n",
    "        # Calculate S-Recall at subcategory level (contextual to categories in the slate)\n",
    "        total_subcategories_in_categories = set()\n",
    "        for category in categories_in_slate:\n",
    "            total_subcategories_in_categories.update(category_to_subcategories[category])\n",
    "        \n",
    "        s_recall_subcategory = len(subcategories_in_slate) / len(total_subcategories_in_categories)\n",
    "        \n",
    "        results.append((s_recall_category, s_recall_subcategory))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Calculate S-Recall for each slate column\n",
    "llm_s_recall = calculate_s_recall(df, 'llm_slate', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "rl_s_recall = calculate_s_recall(df, 'rl_slates', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "slate_reranked_recall = calculate_s_recall(df, 'slate_reranked', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "\n",
    "# Calculate average S-Recall for each column\n",
    "def calculate_average_s_recall(s_recall_results):\n",
    "    avg_category = sum([x[0] for x in s_recall_results]) / len(s_recall_results)\n",
    "    avg_subcategory = sum([x[1] for x in s_recall_results]) / len(s_recall_results)\n",
    "    return avg_category, avg_subcategory\n",
    "\n",
    "llm_avg_category, llm_avg_subcategory = calculate_average_s_recall(llm_s_recall)\n",
    "rl_avg_category, rl_avg_subcategory = calculate_average_s_recall(rl_s_recall)\n",
    "slate_avg_category, slate_avg_subcategory = calculate_average_s_recall(slate_reranked_recall)\n",
    "\n",
    "# Print average S-Recall for each column\n",
    "print(\"Average S-Recall for llm_slate:\")\n",
    "print(f\"Category Level: {llm_avg_category:.4f}, Subcategory Level: {llm_avg_subcategory:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for rl_slates:\")\n",
    "print(f\"Category Level: {rl_avg_category:.4f}, Subcategory Level: {rl_avg_subcategory:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for slate_reranked:\")\n",
    "print(f\"Category Level: {slate_avg_category:.4f}, Subcategory Level: {slate_avg_subcategory:.4f}\")\n",
    "\n",
    "# Calculate number of subcategories for each category\n",
    "subcategory_count = news_df.groupby('category')['subcategory'].nunique().reset_index()\n",
    "subcategory_count.columns = ['category', 'subcategory_count']\n",
    "\n",
    "print(\"\\nNumber of subcategories for each category:\")\n",
    "print(subcategory_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Specialists:\n",
      "Average S-Recall for llm_slate:\n",
      "Category Level: 0.3816, Subcategory Level: 0.0726\n",
      "\n",
      "Average S-Recall for rl_slates:\n",
      "Category Level: 0.5277, Subcategory Level: 0.0614\n",
      "\n",
      "Average S-Recall for slate_reranked:\n",
      "Category Level: 0.4867, Subcategory Level: 0.0594\n",
      "\n",
      "Results for Generalists:\n",
      "Average S-Recall for llm_slate:\n",
      "Category Level: 0.3864, Subcategory Level: 0.0690\n",
      "\n",
      "Average S-Recall for rl_slates:\n",
      "Category Level: 0.5845, Subcategory Level: 0.0592\n",
      "\n",
      "Average S-Recall for slate_reranked:\n",
      "Category Level: 0.5408, Subcategory Level: 0.0571\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame for specialists and generalists\n",
    "specialists_df = df[df['user_type'] == 'specialist'].copy()\n",
    "generalists_df = df[df['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Function to calculate S-Recall for a given DataFrame\n",
    "def calculate_s_recall_for_df(df, column, item_to_category, item_to_subcategory, category_to_subcategories):\n",
    "    results = []\n",
    "    \n",
    "    for slate in df[column]:\n",
    "        categories_in_slate, subcategories_in_slate = calculate_diversity(slate, item_to_category, item_to_subcategory)\n",
    "        \n",
    "        # Calculate S-Recall at category level\n",
    "        s_recall_category = len(categories_in_slate) / len(slate)\n",
    "        \n",
    "        # Calculate S-Recall at subcategory level (contextual to categories in the slate)\n",
    "        total_subcategories_in_categories = set()\n",
    "        for category in categories_in_slate:\n",
    "            total_subcategories_in_categories.update(category_to_subcategories[category])\n",
    "        \n",
    "        s_recall_subcategory = len(subcategories_in_slate) / len(total_subcategories_in_categories)\n",
    "        \n",
    "        results.append((s_recall_category, s_recall_subcategory))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Calculate S-Recall for specialists\n",
    "llm_s_recall_specialists = calculate_s_recall_for_df(specialists_df, 'llm_slate', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "rl_s_recall_specialists = calculate_s_recall_for_df(specialists_df, 'rl_slates', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "slate_reranked_recall_specialists = calculate_s_recall_for_df(specialists_df, 'slate_reranked', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "\n",
    "# Calculate S-Recall for generalists\n",
    "llm_s_recall_generalists = calculate_s_recall_for_df(generalists_df, 'llm_slate', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "rl_s_recall_generalists = calculate_s_recall_for_df(generalists_df, 'rl_slates', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "slate_reranked_recall_generalists = calculate_s_recall_for_df(generalists_df, 'slate_reranked', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "\n",
    "# Function to calculate average S-Recall\n",
    "def calculate_average_s_recall(s_recall_results):\n",
    "    avg_category = sum([x[0] for x in s_recall_results]) / len(s_recall_results)\n",
    "    avg_subcategory = sum([x[1] for x in s_recall_results]) / len(s_recall_results)\n",
    "    return avg_category, avg_subcategory\n",
    "\n",
    "# Calculate average S-Recall for specialists\n",
    "llm_avg_category_specialists, llm_avg_subcategory_specialists = calculate_average_s_recall(llm_s_recall_specialists)\n",
    "rl_avg_category_specialists, rl_avg_subcategory_specialists = calculate_average_s_recall(rl_s_recall_specialists)\n",
    "slate_avg_category_specialists, slate_avg_subcategory_specialists = calculate_average_s_recall(slate_reranked_recall_specialists)\n",
    "\n",
    "# Calculate average S-Recall for generalists\n",
    "llm_avg_category_generalists, llm_avg_subcategory_generalists = calculate_average_s_recall(llm_s_recall_generalists)\n",
    "rl_avg_category_generalists, rl_avg_subcategory_generalists = calculate_average_s_recall(rl_s_recall_generalists)\n",
    "slate_avg_category_generalists, slate_avg_subcategory_generalists = calculate_average_s_recall(slate_reranked_recall_generalists)\n",
    "\n",
    "# Print results for specialists\n",
    "print(\"Results for Specialists:\")\n",
    "print(\"Average S-Recall for llm_slate:\")\n",
    "print(f\"Category Level: {llm_avg_category_specialists:.4f}, Subcategory Level: {llm_avg_subcategory_specialists:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for rl_slates:\")\n",
    "print(f\"Category Level: {rl_avg_category_specialists:.4f}, Subcategory Level: {rl_avg_subcategory_specialists:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for slate_reranked:\")\n",
    "print(f\"Category Level: {slate_avg_category_specialists:.4f}, Subcategory Level: {slate_avg_subcategory_specialists:.4f}\")\n",
    "\n",
    "# Print results for generalists\n",
    "print(\"\\nResults for Generalists:\")\n",
    "print(\"Average S-Recall for llm_slate:\")\n",
    "print(f\"Category Level: {llm_avg_category_generalists:.4f}, Subcategory Level: {llm_avg_subcategory_generalists:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for rl_slates:\")\n",
    "print(f\"Category Level: {rl_avg_category_generalists:.4f}, Subcategory Level: {rl_avg_subcategory_generalists:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for slate_reranked:\")\n",
    "print(f\"Category Level: {slate_avg_category_generalists:.4f}, Subcategory Level: {slate_avg_subcategory_generalists:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_data_user_history = category_data.merge(\n",
    "    df,\n",
    "    left_on=['click', 'observed_state'],\n",
    "    right_on=['original_click', 'initial_user_state_tuple'],\n",
    "    how='right'  # Use 'inner' to keep only matching rows\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract titles from the list of tuples\n",
    "def extract_titles(item_tuples):\n",
    "    return [title for (_, title) in item_tuples]\n",
    "\n",
    "# Function to compute BLEU score between two lists of titles\n",
    "def compute_bleu_score(reference, candidate):\n",
    "    reference_tokens = [word_tokenize(str(title)) for title in reference]\n",
    "    candidate_tokens = word_tokenize(str(candidate[0]))  # Ensure candidate is a single tokenized sentence\n",
    "    \n",
    "    # Compute BLEU score\n",
    "    smoothing = SmoothingFunction().method1\n",
    "    return sentence_bleu(reference_tokens, candidate_tokens, smoothing_function=smoothing)\n",
    "# Compute BLEU scores for each row\n",
    "clicked_data_user_history['bleu_rl_vs_presented'] = clicked_data_user_history.apply(\n",
    "    lambda row: compute_bleu_score(\n",
    "        extract_titles(get_item_ids_and_titles(row['presented_slate'], news_df)),\n",
    "        extract_titles(get_item_ids_and_titles(row['rl_slates'], news_df)),  # Replace None with your news_df# Replace None with your news_df\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "clicked_data_user_history['bleu_llm_vs_presented'] = clicked_data_user_history.apply(\n",
    "    lambda row: compute_bleu_score(\n",
    "        extract_titles(get_item_ids_and_titles(row['presented_slate'], news_df)) ,\n",
    "        extract_titles(get_item_ids_and_titles(row['llm_slate'], news_df)),  # Replace None with your news_df# Replace None with your news_df\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "clicked_data_user_history['bleu_reranked_vs_presented'] = clicked_data_user_history.apply(\n",
    "    lambda row: compute_bleu_score(\n",
    "        extract_titles(get_item_ids_and_titles(row['presented_slate'], news_df)) ,\n",
    "        extract_titles(get_item_ids_and_titles(row['slate_reranked'], news_df)),  # Replace None with your news_df# Replace None with your news_df\n",
    "    ), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  \\\n",
      "0   (-0.0259791798889637, 0.5851805210113525, 0.00...   \n",
      "1   (0.049241334199905396, 0.23491184413433075, 0....   \n",
      "2   (0.06917192041873932, 0.22154483199119568, 0.0...   \n",
      "3   (0.0808219462633133, 0.280564546585083, -0.035...   \n",
      "4   (0.11326862126588821, 0.38108861446380615, -0....   \n",
      "..                                                ...   \n",
      "95  (0.3616601228713989, 0.1373804360628128, 0.021...   \n",
      "96  (0.3617928624153137, 0.11457429826259613, 0.01...   \n",
      "97  (0.36578845977783203, 0.042487733066082, 0.081...   \n",
      "98  (0.39353927969932556, 0.0698390007019043, -0.0...   \n",
      "99  (0.3967207372188568, 0.18588663637638092, -0.0...   \n",
      "\n",
      "    group_mean_bleu_rl_vs_presented  \n",
      "0                          1.000000  \n",
      "1                          0.348927  \n",
      "2                          0.020448  \n",
      "3                          0.027184  \n",
      "4                          0.109868  \n",
      "..                              ...  \n",
      "95                         0.024141  \n",
      "96                         0.021650  \n",
      "97                         0.347751  \n",
      "98                         0.346025  \n",
      "99                         0.031673  \n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.2344573408738\n"
     ]
    }
   ],
   "source": [
    "grouped_means_bleu_rl = clicked_data_user_history.groupby('initial_user_state_tuple')['bleu_rl_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_rl.rename(columns={'bleu_rl_vs_presented': 'group_mean_bleu_rl_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_bleu_rl['group_mean_bleu_rl_vs_presented'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_bleu_rl)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for specialists and generalists\n",
    "specialists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'specialist'].copy()\n",
    "generalists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 1: Group by initial_user_state_tuple and calculate the mean of bleu_rl_vs_presented for specialists\n",
    "grouped_means_bleu_rl_specialists = specialists_data.groupby('initial_user_state_tuple')['bleu_rl_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_rl_specialists.rename(columns={'bleu_rl_vs_presented': 'group_mean_bleu_rl_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of bleu_rl_vs_presented for generalists\n",
    "grouped_means_bleu_rl_generalists = generalists_data.groupby('initial_user_state_tuple')['bleu_rl_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_rl_generalists.rename(columns={'bleu_rl_vs_presented': 'group_mean_bleu_rl_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means for specialists and generalists\n",
    "overall_mean_specialists = grouped_means_bleu_rl_specialists['group_mean_bleu_rl_vs_presented'].mean()\n",
    "overall_mean_generalists = grouped_means_bleu_rl_generalists['group_mean_bleu_rl_vs_presented'].mean()\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  \\\n",
      "0   (-0.0259791798889637, 0.5851805210113525, 0.00...   \n",
      "1   (0.049241334199905396, 0.23491184413433075, 0....   \n",
      "2   (0.06917192041873932, 0.22154483199119568, 0.0...   \n",
      "3   (0.0808219462633133, 0.280564546585083, -0.035...   \n",
      "4   (0.11326862126588821, 0.38108861446380615, -0....   \n",
      "..                                                ...   \n",
      "95  (0.3616601228713989, 0.1373804360628128, 0.021...   \n",
      "96  (0.3617928624153137, 0.11457429826259613, 0.01...   \n",
      "97  (0.36578845977783203, 0.042487733066082, 0.081...   \n",
      "98  (0.39353927969932556, 0.0698390007019043, -0.0...   \n",
      "99  (0.3967207372188568, 0.18588663637638092, -0.0...   \n",
      "\n",
      "    group_mean_bleu_reranked_vs_presented  \n",
      "0                                0.274076  \n",
      "1                                0.348927  \n",
      "2                                0.019641  \n",
      "3                                0.168887  \n",
      "4                                0.308249  \n",
      "..                                    ...  \n",
      "95                               0.037544  \n",
      "96                               0.216883  \n",
      "97                               0.683414  \n",
      "98                               0.348115  \n",
      "99                               0.026354  \n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.22636164752225274\n"
     ]
    }
   ],
   "source": [
    "grouped_means_bleu_bm25 = clicked_data_user_history.groupby('initial_user_state_tuple')['bleu_reranked_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_bm25.rename(columns={'bleu_reranked_vs_presented': 'group_mean_bleu_reranked_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_bleu_bm25['group_mean_bleu_reranked_vs_presented'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_bleu_bm25)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for specialists and generalists\n",
    "specialists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'specialist'].copy()\n",
    "generalists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 1: Group by initial_user_state_tuple and calculate the mean of bleu_reranked_vs_presented for specialists\n",
    "grouped_means_bleu_rl_specialists = specialists_data.groupby('initial_user_state_tuple')['bleu_reranked_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_rl_specialists.rename(columns={'bleu_reranked_vs_presented': 'group_mean_bleu_reranked_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of bleu_reranked_vs_presented for generalists\n",
    "grouped_means_bleu_rl_generalists = generalists_data.groupby('initial_user_state_tuple')['bleu_reranked_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_rl_generalists.rename(columns={'bleu_reranked_vs_presented': 'group_mean_bleu_reranked_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means for specialists and generalists\n",
    "overall_mean_specialists = grouped_means_bleu_rl_specialists['group_mean_bleu_reranked_vs_presented'].mean()\n",
    "overall_mean_generalists = grouped_means_bleu_rl_generalists['group_mean_bleu_reranked_vs_presented'].mean()\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  \\\n",
      "0   (-0.0259791798889637, 0.5851805210113525, 0.00...   \n",
      "1   (0.049241334199905396, 0.23491184413433075, 0....   \n",
      "2   (0.06917192041873932, 0.22154483199119568, 0.0...   \n",
      "3   (0.0808219462633133, 0.280564546585083, -0.035...   \n",
      "4   (0.11326862126588821, 0.38108861446380615, -0....   \n",
      "..                                                ...   \n",
      "95  (0.3616601228713989, 0.1373804360628128, 0.021...   \n",
      "96  (0.3617928624153137, 0.11457429826259613, 0.01...   \n",
      "97  (0.36578845977783203, 0.042487733066082, 0.081...   \n",
      "98  (0.39353927969932556, 0.0698390007019043, -0.0...   \n",
      "99  (0.3967207372188568, 0.18588663637638092, -0.0...   \n",
      "\n",
      "    group_mean_bleu_llm_vs_presented  \n",
      "0                           1.000000  \n",
      "1                           0.021973  \n",
      "2                           0.024448  \n",
      "3                           0.041316  \n",
      "4                           0.603001  \n",
      "..                               ...  \n",
      "95                          0.018477  \n",
      "96                          0.023419  \n",
      "97                          0.364739  \n",
      "98                          0.022325  \n",
      "99                          1.000000  \n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.4068742021401646\n"
     ]
    }
   ],
   "source": [
    "grouped_means_bleu_llm = clicked_data_user_history.groupby('initial_user_state_tuple')['bleu_llm_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_llm.rename(columns={'bleu_llm_vs_presented': 'group_mean_bleu_llm_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_bleu_llm['group_mean_bleu_llm_vs_presented'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_bleu_llm)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for specialists and generalists\n",
    "specialists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'specialist'].copy()\n",
    "generalists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 1: Group by initial_user_state_tuple and calculate the mean of bleu_llm_vs_presented for specialists\n",
    "grouped_means_bleu_llm_specialists = specialists_data.groupby('initial_user_state_tuple')['bleu_llm_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_llm_specialists.rename(columns={'bleu_llm_vs_presented': 'group_mean_bleu_llm_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of bleu_llm_vs_presented for generalists\n",
    "grouped_means_bleu_llm_generalists = generalists_data.groupby('initial_user_state_tuple')['bleu_llm_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_llm_generalists.rename(columns={'bleu_llm_vs_presented': 'group_mean_bleu_llm_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means for specialists and generalists\n",
    "overall_mean_specialists = grouped_means_bleu_llm_specialists['group_mean_bleu_llm_vs_presented'].mean()\n",
    "overall_mean_generalists = grouped_means_bleu_llm_generalists['group_mean_bleu_llm_vs_presented'].mean()\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "feather_file_path_slateq= gen_slates_dir / \"slateq_llm_slates.feather\"\n",
    "df_slateq = pd.read_feather(feather_file_path_slateq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slateq['initial_user_state_tuple'] = df_slateq['initial_user_state'].apply(tuple)\n",
    "# Step 2: Merge with df_slateq based on the matching condition\n",
    "df_slateq = pd.merge(\n",
    "    df_slateq,\n",
    "    click_history_data,\n",
    "    left_on='initial_user_state_tuple',\n",
    "    right_on='observed_state',\n",
    "    how='left'  # Use 'left' to keep all rows from df_slateq, or 'inner' for only matching rows\n",
    ")\n",
    "\n",
    "# Drop the extra 'observed_state' column if you don't need it\n",
    "df_slateq = df_slateq.drop(columns=['observed_state'])\n",
    "df_slateq['diversity_score']=df_slateq.apply(entropy_based_diversity,axis=1)\n",
    "q1 = df_slateq['diversity_score'].quantile(0.25)\n",
    "conditions = [\n",
    "    df_slateq['diversity_score'] == 0,  # Cold\n",
    "    df_slateq['diversity_score'] <= q1,  # Specialist\n",
    "    df_slateq['diversity_score'] > q1    # Generalist\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    'cold',\n",
    "    'specialist',\n",
    "    'generalist'\n",
    "]\n",
    "\n",
    "# Step 3: Use numpy.select to apply the conditions\n",
    "df_slateq['user_type'] = np.select(conditions, choices, default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  group_mean_hit\n",
      "0   (0.13400940597057343, 0.2015896886587143, -0.0...            0.00\n",
      "1   (0.15157544612884521, 0.33397215604782104, -0....            1.00\n",
      "2   (0.15727820992469788, 0.2477571815252304, -0.1...            0.00\n",
      "3   (0.1577419489622116, 0.21108318865299225, -0.0...            1.00\n",
      "4   (0.15791304409503937, 0.29125070571899414, -0....            0.00\n",
      "..                                                ...             ...\n",
      "95  (0.2903972268104553, 0.15165531635284424, -0.0...            0.25\n",
      "96  (0.2935115098953247, 0.13266007602214813, -0.1...            0.00\n",
      "97  (0.29664674401283264, 0.14605002105236053, 0.0...            0.00\n",
      "98  (0.29784202575683594, 0.2651831805706024, 0.01...            0.00\n",
      "99  (0.2985374331474304, 0.1253967434167862, 0.048...            0.00\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.1322950558213716\n"
     ]
    }
   ],
   "source": [
    "df_slateq= df_slateq[df_slateq['llm_slateq_slate'].apply(lambda x: len(x) > 0)].copy()\n",
    "df_slateq['initial_user_state_tuple'] = df_slateq['initial_user_state'].apply(tuple)\n",
    "\n",
    "# Step 2: Group by initial_user_state and calculate the mean of 'hit' for each group\n",
    "grouped_means_slateq_llm = df_slateq.groupby('initial_user_state_tuple')['slateq_hit'].mean().reset_index()\n",
    "grouped_means_slateq_llm.rename(columns={'slateq_hit': 'group_mean_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_slateq_llm['group_mean_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_slateq_llm)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter the DataFrame for specialists and generalists\n",
    "specialists_df = df_slateq[df_slateq['user_type'] == 'specialist'].copy()\n",
    "generalists_df = df_slateq[df_slateq['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of 'slateq_hit' for each group\n",
    "# For specialists\n",
    "grouped_means_specialists = specialists_df.groupby('initial_user_state_tuple')['slateq_hit'].mean().reset_index()\n",
    "grouped_means_specialists.rename(columns={'slateq_hit': 'group_mean_slateq_hit'}, inplace=True)\n",
    "\n",
    "# For generalists\n",
    "grouped_means_generalists = generalists_df.groupby('initial_user_state_tuple')['slateq_hit'].mean().reset_index()\n",
    "grouped_means_generalists.rename(columns={'slateq_hit': 'group_mean_slateq_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "# For specialists\n",
    "overall_mean_specialists = grouped_means_specialists['group_mean_slateq_hit'].mean()\n",
    "\n",
    "# For generalists\n",
    "overall_mean_generalists = grouped_means_generalists['group_mean_slateq_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "# print(\"Group-level averages for Specialists:\")\n",
    "# print(grouped_means_specialists)\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "# print(\"\\nGroup-level averages for Generalists:\")\n",
    "# print(grouped_means_generalists)\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slateq['slateq_slates'] = [\n",
    "    [embedding_lookup.get(tuple(embedding), \"Not Found\") for embedding in slate_list]\n",
    "    for slate_list in df_slateq['slate_docs_feature']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slateq['actual_slateq_hit'] = df_slateq.apply(lambda row: 1 if row['original_click'] in row['slateq_slates'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  \\\n",
      "0   (0.13400940597057343, 0.2015896886587143, -0.0...   \n",
      "1   (0.15157544612884521, 0.33397215604782104, -0....   \n",
      "2   (0.15727820992469788, 0.2477571815252304, -0.1...   \n",
      "3   (0.1577419489622116, 0.21108318865299225, -0.0...   \n",
      "4   (0.15791304409503937, 0.29125070571899414, -0....   \n",
      "..                                                ...   \n",
      "95  (0.2903972268104553, 0.15165531635284424, -0.0...   \n",
      "96  (0.2935115098953247, 0.13266007602214813, -0.1...   \n",
      "97  (0.29664674401283264, 0.14605002105236053, 0.0...   \n",
      "98  (0.29784202575683594, 0.2651831805706024, 0.01...   \n",
      "99  (0.2985374331474304, 0.1253967434167862, 0.048...   \n",
      "\n",
      "    group_mean_actual_slateq_hit  \n",
      "0                            0.0  \n",
      "1                            0.0  \n",
      "2                            0.5  \n",
      "3                            0.0  \n",
      "4                            0.0  \n",
      "..                           ...  \n",
      "95                           0.0  \n",
      "96                           0.0  \n",
      "97                           0.0  \n",
      "98                           0.5  \n",
      "99                           0.0  \n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.06604835807467387\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Group by initial_user_state and calculate the mean of 'hit' for each group\n",
    "grouped_means_slateq = df_slateq.groupby('initial_user_state_tuple')['actual_slateq_hit'].mean().reset_index()\n",
    "grouped_means_slateq.rename(columns={'actual_slateq_hit': 'group_mean_actual_slateq_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_slateq['group_mean_actual_slateq_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_slateq)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter the DataFrame for specialists and generalists\n",
    "specialists_df = df_slateq[df_slateq['user_type'] == 'specialist'].copy()\n",
    "generalists_df = df_slateq[df_slateq['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of 'actual_slateq_hit' for each group\n",
    "# For specialists\n",
    "grouped_means_specialists = specialists_df.groupby('initial_user_state_tuple')['actual_slateq_hit'].mean().reset_index()\n",
    "grouped_means_specialists.rename(columns={'actual_slateq_hit': 'group_mean_actual_slateq_hit'}, inplace=True)\n",
    "\n",
    "# For generalists\n",
    "grouped_means_generalists = generalists_df.groupby('initial_user_state_tuple')['actual_slateq_hit'].mean().reset_index()\n",
    "grouped_means_generalists.rename(columns={'actual_slateq_hit': 'group_mean_actual_slateq_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "# For specialists\n",
    "overall_mean_specialists = grouped_means_specialists['group_mean_actual_slateq_hit'].mean()\n",
    "\n",
    "# For generalists\n",
    "overall_mean_generalists = grouped_means_generalists['group_mean_actual_slateq_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "# print(\"Group-level averages for Specialists:\")\n",
    "# print(grouped_means_specialists)\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "# print(\"\\nGroup-level averages for Generalists:\")\n",
    "# print(grouped_means_generalists)\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df_filtered = df_filtered.reset_index(drop=True)\n",
    "\n",
    "def hybrid_slate_optimization(row):\n",
    "    \"\"\"\n",
    "    Replaces the 3 least relevant items in the slate using a hybrid BM25 + cosine similarity approach.\n",
    "\n",
    "    Args:\n",
    "        row: A row from the DataFrame (passed via df.apply).\n",
    "\n",
    "    Returns:\n",
    "        Updated slate as a list of item IDs.\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve item IDs using the embedding lookup\n",
    "    slate_item_ids = [embedding_lookup.get(tuple(embedding), \"Not Found\") for embedding in row[\"slate_docs_feature\"]]\n",
    "    candidate_item_ids = [embedding_lookup.get(tuple(embedding), \"Not Found\") for embedding in row[\"candidate_docs\"]]\n",
    "\n",
    "    # Get titles for slate and candidate items\n",
    "    slate_titles = [title for _, title in get_item_ids_and_titles(slate_item_ids, news_df)]\n",
    "    candidate_titles = [title for _, title in get_item_ids_and_titles(candidate_item_ids, news_df)]\n",
    "    \n",
    "\n",
    "    # Tokenize titles for BM25\n",
    "    slate_tokens = [text.split() for text in slate_titles]\n",
    "    candidate_tokens = [text.split() for text in candidate_titles]\n",
    "    \n",
    "    bm25 = BM25Okapi(candidate_tokens)\n",
    "    bm25_scores = np.array([bm25.get_scores(tokens) for tokens in slate_tokens])  # (N, M)\n",
    "\n",
    "    # Compute Cosine Similarity scores\n",
    "    candidate_docs_matrix = np.array(row[\"candidate_docs\"])  # Convert to 2D numpy array\n",
    "    candidate_docs_matrix = np.vstack(row[\"candidate_docs\"])\n",
    "    slate_docs_feature_matrix = np.array(row[\"slate_docs_feature\"])  # Convert to 2D numpy array\n",
    "    slate_docs_feature_matrix = np.vstack(row[\"slate_docs_feature\"])\n",
    "\n",
    "    similarity_matrix = cosine_similarity(slate_docs_feature_matrix,candidate_docs_matrix)  # (M, N)\n",
    "    \n",
    "   \n",
    "   \n",
    "    # Normalize and Combine Scores\n",
    "    lambda_weight = 1.0  # Adjust balance between BM25 and cosine similarity\n",
    "    bm25_norm = (bm25_scores - bm25_scores.min()) / (bm25_scores.max() - bm25_scores.min() + 1e-6)\n",
    "    # bm25_norm = bm25_norm.T \n",
    "    cosine_norm = (similarity_matrix - similarity_matrix.min()) / (similarity_matrix.max() - similarity_matrix.min() + 1e-6)\n",
    "  \n",
    "    final_scores = lambda_weight * bm25_norm + (1 - lambda_weight) * cosine_norm  # (N, M)\n",
    "    \n",
    "\n",
    "    # Identify 3 least relevant slate items\n",
    "    avg_slate_relevance = final_scores.mean(axis=1)  # Average score per slate item\n",
    "    least_relevant_indices = np.argsort(avg_slate_relevance)[:9]  # Indices of 3 least relevant slate items\n",
    "\n",
    "    # Select 3 best candidates\n",
    "    best_candidate_indices = np.argsort(final_scores.max(axis=0))[-9:]  # Indices of top 3 candidates\n",
    "\n",
    "    # Replace the least relevant slate items with best candidates\n",
    "    updated_slate_item_ids = slate_item_ids[:]\n",
    "    for slate_idx, candidate_idx in zip(least_relevant_indices, best_candidate_indices):\n",
    "        updated_slate_item_ids[slate_idx] = candidate_item_ids[candidate_idx]  # Replace with best candidate ID\n",
    "    \n",
    "\n",
    "    return updated_slate_item_ids\n",
    "\n",
    "# Apply function to DataFrame\n",
    "\n",
    "df_slateq[\"slateq_reranked\"] = df_slateq.apply(hybrid_slate_optimization, axis=1)\n",
    "\n",
    "\n",
    "# # Save the updated DataFrame\n",
    "# df.to_csv(\"updated_slate_data.csv\", index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slateq['slateq_reranked_hit'] = df_slateq.apply(lambda row: 1 if row['original_click'] in row['slateq_reranked'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  \\\n",
      "0   (0.13400940597057343, 0.2015896886587143, -0.0...   \n",
      "1   (0.15157544612884521, 0.33397215604782104, -0....   \n",
      "2   (0.15727820992469788, 0.2477571815252304, -0.1...   \n",
      "3   (0.1577419489622116, 0.21108318865299225, -0.0...   \n",
      "4   (0.15791304409503937, 0.29125070571899414, -0....   \n",
      "..                                                ...   \n",
      "95  (0.2903972268104553, 0.15165531635284424, -0.0...   \n",
      "96  (0.2935115098953247, 0.13266007602214813, -0.1...   \n",
      "97  (0.29664674401283264, 0.14605002105236053, 0.0...   \n",
      "98  (0.29784202575683594, 0.2651831805706024, 0.01...   \n",
      "99  (0.2985374331474304, 0.1253967434167862, 0.048...   \n",
      "\n",
      "    group_mean_slateq_reranked_hit  \n",
      "0                              0.0  \n",
      "1                              0.0  \n",
      "2                              0.5  \n",
      "3                              0.0  \n",
      "4                              0.0  \n",
      "..                             ...  \n",
      "95                             0.0  \n",
      "96                             0.0  \n",
      "97                             0.0  \n",
      "98                             0.5  \n",
      "99                             0.0  \n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.053715024741340524\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Group by initial_user_state and calculate the mean of 'hit' for each group\n",
    "grouped_means_bm25_slateq = df_slateq.groupby('initial_user_state_tuple')['slateq_reranked_hit'].mean().reset_index()\n",
    "grouped_means_bm25_slateq.rename(columns={'slateq_reranked_hit': 'group_mean_slateq_reranked_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_bm25_slateq['group_mean_slateq_reranked_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_bm25_slateq)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter the DataFrame for specialists and generalists\n",
    "specialists_df = df_slateq[df_slateq['user_type'] == 'specialist'].copy()\n",
    "generalists_df = df_slateq[df_slateq['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of 'slateq_reranked_hit' for each group\n",
    "# For specialists\n",
    "grouped_means_specialists = specialists_df.groupby('initial_user_state_tuple')['slateq_reranked_hit'].mean().reset_index()\n",
    "grouped_means_specialists.rename(columns={'slateq_reranked_hit': 'group_mean_slateq_hit'}, inplace=True)\n",
    "\n",
    "# For generalists\n",
    "grouped_means_generalists = generalists_df.groupby('initial_user_state_tuple')['slateq_reranked_hit'].mean().reset_index()\n",
    "grouped_means_generalists.rename(columns={'slateq_reranked_hit': 'group_mean_slateq_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "# For specialists\n",
    "overall_mean_specialists = grouped_means_specialists['group_mean_slateq_hit'].mean()\n",
    "\n",
    "# For generalists\n",
    "overall_mean_generalists = grouped_means_generalists['group_mean_slateq_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "# print(\"Group-level averages for Specialists:\")\n",
    "# print(grouped_means_specialists)\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "# print(\"\\nGroup-level averages for Generalists:\")\n",
    "# print(grouped_means_generalists)\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average S-Recall for llm_slate:\n",
      "Category Level: 0.5199, Subcategory Level: 0.7714\n",
      "\n",
      "Average S-Recall for rl_slates:\n",
      "Category Level: 0.6162, Subcategory Level: 0.8601\n",
      "\n",
      "Average S-Recall for slate_reranked:\n",
      "Category Level: 0.5789, Subcategory Level: 0.7809\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary for quick lookup of category and subcategory\n",
    "item_to_category = dict(zip(news_df['itemId'], news_df['category']))\n",
    "item_to_subcategory = dict(zip(news_df['itemId'], news_df['subcategory']))\n",
    "\n",
    "# Calculate total unique categories and subcategories in the dataset\n",
    "total_categories = news_df['category'].nunique()\n",
    "total_subcategories = news_df['subcategory'].nunique()\n",
    "\n",
    "# Function to calculate diversity metrics for a given slate\n",
    "def calculate_diversity(slate, item_to_category, item_to_subcategory):\n",
    "    categories = set()\n",
    "    subcategories = set()\n",
    "    \n",
    "    for item in slate:\n",
    "        if item in item_to_category:\n",
    "            categories.add(item_to_category[item])\n",
    "        if item in item_to_subcategory:\n",
    "            subcategories.add(item_to_subcategory[item])\n",
    "    \n",
    "    return len(categories), len(subcategories)\n",
    "\n",
    "# Function to calculate S-Recall as a ratio\n",
    "def calculate_s_recall(df, column, item_to_category, item_to_subcategory, total_categories, total_subcategories):\n",
    "    results = []\n",
    "    \n",
    "    for slate in df[column]:\n",
    "        category_diversity, subcategory_diversity = calculate_diversity(slate, item_to_category, item_to_subcategory)\n",
    "        \n",
    "        # Calculate S-Recall as a ratio\n",
    "        s_recall_category = category_diversity / len(slate)\n",
    "        s_recall_subcategory = subcategory_diversity / len(slate)\n",
    "        \n",
    "        results.append((s_recall_category, s_recall_subcategory))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Calculate S-Recall for each slate column\n",
    "llm_s_recall = calculate_s_recall(df_slateq, 'llm_slateq_slate', item_to_category, item_to_subcategory, total_categories, total_subcategories)\n",
    "rl_s_recall = calculate_s_recall(df_slateq, 'slateq_slates', item_to_category, item_to_subcategory, total_categories, total_subcategories)\n",
    "slate_reranked_recall = calculate_s_recall(df_slateq, 'slateq_reranked', item_to_category, item_to_subcategory, total_categories, total_subcategories)\n",
    "\n",
    "# Calculate average S-Recall for each column\n",
    "def calculate_average_s_recall(s_recall_results):\n",
    "    avg_category = sum([x[0] for x in s_recall_results]) / len(s_recall_results)\n",
    "    avg_subcategory = sum([x[1] for x in s_recall_results]) / len(s_recall_results)\n",
    "    return avg_category, avg_subcategory\n",
    "\n",
    "llm_avg_category, llm_avg_subcategory = calculate_average_s_recall(llm_s_recall)\n",
    "rl_avg_category, rl_avg_subcategory = calculate_average_s_recall(rl_s_recall)\n",
    "slate_avg_category, slate_avg_subcategory = calculate_average_s_recall(slate_reranked_recall)\n",
    "\n",
    "# Print average S-Recall for each column\n",
    "print(\"Average S-Recall for llm_slate:\")\n",
    "print(f\"Category Level: {llm_avg_category:.4f}, Subcategory Level: {llm_avg_subcategory:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for rl_slates:\")\n",
    "print(f\"Category Level: {rl_avg_category:.4f}, Subcategory Level: {rl_avg_subcategory:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for slate_reranked:\")\n",
    "print(f\"Category Level: {slate_avg_category:.4f}, Subcategory Level: {slate_avg_subcategory:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average S-Recall for llm_slate:\n",
      "Category Level: 0.5199, Subcategory Level: 0.0638\n",
      "\n",
      "Average S-Recall for rl_slates:\n",
      "Category Level: 0.6162, Subcategory Level: 0.0602\n",
      "\n",
      "Average S-Recall for slate_reranked:\n",
      "Category Level: 0.5789, Subcategory Level: 0.0575\n",
      "\n",
      "Number of subcategories for each category:\n",
      "         category  subcategory_count\n",
      "0           autos                 25\n",
      "1   entertainment                 14\n",
      "2         finance                 33\n",
      "3    foodanddrink                 16\n",
      "4           games                  1\n",
      "5          health                 23\n",
      "6            kids                  6\n",
      "7       lifestyle                 53\n",
      "8      middleeast                  1\n",
      "9          movies                  7\n",
      "10          music                 11\n",
      "11           news                 38\n",
      "12   northamerica                  1\n",
      "13         sports                 34\n",
      "14         travel                 16\n",
      "15             tv                 10\n",
      "16          video                 15\n",
      "17        weather                  3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a dictionary to map categories to their subcategories\n",
    "category_to_subcategories = news_df.groupby('category')['subcategory'].unique().to_dict()\n",
    "\n",
    "# Function to calculate diversity metrics for a given slate\n",
    "def calculate_diversity(slate, item_to_category, item_to_subcategory):\n",
    "    categories = set()\n",
    "    subcategories = set()\n",
    "    \n",
    "    for item in slate:\n",
    "        if item in item_to_category:\n",
    "            categories.add(item_to_category[item])\n",
    "        if item in item_to_subcategory:\n",
    "            subcategories.add(item_to_subcategory[item])\n",
    "    \n",
    "    return categories, subcategories\n",
    "\n",
    "# Function to calculate S-Recall as a ratio\n",
    "def calculate_s_recall(df, column, item_to_category, item_to_subcategory, category_to_subcategories):\n",
    "    results = []\n",
    "    \n",
    "    for slate in df[column]:\n",
    "        categories_in_slate, subcategories_in_slate = calculate_diversity(slate, item_to_category, item_to_subcategory)\n",
    "        \n",
    "        # Calculate S-Recall at category level\n",
    "        s_recall_category = len(categories_in_slate) / len(slate)\n",
    "        \n",
    "        # Calculate S-Recall at subcategory level (contextual to categories in the slate)\n",
    "        total_subcategories_in_categories = set()\n",
    "        for category in categories_in_slate:\n",
    "            total_subcategories_in_categories.update(category_to_subcategories[category])\n",
    "        \n",
    "        s_recall_subcategory = len(subcategories_in_slate) / len(total_subcategories_in_categories)\n",
    "        \n",
    "        results.append((s_recall_category, s_recall_subcategory))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Calculate S-Recall for each slate column\n",
    "llm_s_recall = calculate_s_recall(df_slateq, 'llm_slateq_slate', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "rl_s_recall = calculate_s_recall(df_slateq, 'slateq_slates', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "slate_reranked_recall = calculate_s_recall(df_slateq, 'slateq_reranked', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "\n",
    "# Calculate average S-Recall for each column\n",
    "def calculate_average_s_recall(s_recall_results):\n",
    "    avg_category = sum([x[0] for x in s_recall_results]) / len(s_recall_results)\n",
    "    avg_subcategory = sum([x[1] for x in s_recall_results]) / len(s_recall_results)\n",
    "    return avg_category, avg_subcategory\n",
    "\n",
    "llm_avg_category, llm_avg_subcategory = calculate_average_s_recall(llm_s_recall)\n",
    "rl_avg_category, rl_avg_subcategory = calculate_average_s_recall(rl_s_recall)\n",
    "slate_avg_category, slate_avg_subcategory = calculate_average_s_recall(slate_reranked_recall)\n",
    "\n",
    "# Print average S-Recall for each column\n",
    "print(\"Average S-Recall for llm_slate:\")\n",
    "print(f\"Category Level: {llm_avg_category:.4f}, Subcategory Level: {llm_avg_subcategory:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for rl_slates:\")\n",
    "print(f\"Category Level: {rl_avg_category:.4f}, Subcategory Level: {rl_avg_subcategory:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for slate_reranked:\")\n",
    "print(f\"Category Level: {slate_avg_category:.4f}, Subcategory Level: {slate_avg_subcategory:.4f}\")\n",
    "\n",
    "# Calculate number of subcategories for each category\n",
    "subcategory_count = news_df.groupby('category')['subcategory'].nunique().reset_index()\n",
    "subcategory_count.columns = ['category', 'subcategory_count']\n",
    "\n",
    "print(\"\\nNumber of subcategories for each category:\")\n",
    "print(subcategory_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for specialists and generalists\n",
    "specialists_df = df_slateq[df_slateq['user_type'] == 'specialist'].copy()\n",
    "generalists_df = df_slateq[df_slateq['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Function to calculate S-Recall for a given DataFrame\n",
    "def calculate_s_recall_for_df(df_slateq, column, item_to_category, item_to_subcategory, category_to_subcategories):\n",
    "    results = []\n",
    "    \n",
    "    for slate in df_slateq[column]:\n",
    "        categories_in_slate, subcategories_in_slate = calculate_diversity(slate, item_to_category, item_to_subcategory)\n",
    "        \n",
    "        # Calculate S-Recall at category level\n",
    "        s_recall_category = len(categories_in_slate) / len(slate)\n",
    "        \n",
    "        # Calculate S-Recall at subcategory level (contextual to categories in the slate)\n",
    "        total_subcategories_in_categories = set()\n",
    "        for category in categories_in_slate:\n",
    "            total_subcategories_in_categories.update(category_to_subcategories[category])\n",
    "        \n",
    "        s_recall_subcategory = len(subcategories_in_slate) / len(total_subcategories_in_categories)\n",
    "        \n",
    "        results.append((s_recall_category, s_recall_subcategory))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Calculate S-Recall for specialists\n",
    "llm_s_recall_specialists = calculate_s_recall_for_df(specialists_df, 'llm_slateq_slate', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "rl_s_recall_specialists = calculate_s_recall_for_df(specialists_df, 'slateq_slates', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "slate_reranked_recall_specialists = calculate_s_recall_for_df(specialists_df, 'slateq_reranked', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "\n",
    "# Calculate S-Recall for generalists\n",
    "llm_s_recall_generalists = calculate_s_recall_for_df(generalists_df, 'llm_slateq_slate', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "rl_s_recall_generalists = calculate_s_recall_for_df(generalists_df, 'slateq_slates', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "slate_reranked_recall_generalists = calculate_s_recall_for_df(generalists_df, 'slateq_reranked', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "\n",
    "# Function to calculate average S-Recall\n",
    "def calculate_average_s_recall(s_recall_results):\n",
    "    avg_category = sum([x[0] for x in s_recall_results]) / len(s_recall_results)\n",
    "    avg_subcategory = sum([x[1] for x in s_recall_results]) / len(s_recall_results)\n",
    "    return avg_category, avg_subcategory\n",
    "\n",
    "# Calculate average S-Recall for specialists\n",
    "llm_avg_category_specialists, llm_avg_subcategory_specialists = calculate_average_s_recall(llm_s_recall_specialists)\n",
    "rl_avg_category_specialists, rl_avg_subcategory_specialists = calculate_average_s_recall(rl_s_recall_specialists)\n",
    "slate_avg_category_specialists, slate_avg_subcategory_specialists = calculate_average_s_recall(slate_reranked_recall_specialists)\n",
    "\n",
    "# Calculate average S-Recall for generalists\n",
    "llm_avg_category_generalists, llm_avg_subcategory_generalists = calculate_average_s_recall(llm_s_recall_generalists)\n",
    "rl_avg_category_generalists, rl_avg_subcategory_generalists = calculate_average_s_recall(rl_s_recall_generalists)\n",
    "slate_avg_category_generalists, slate_avg_subcategory_generalists = calculate_average_s_recall(slate_reranked_recall_generalists)\n",
    "\n",
    "# Print results for specialists\n",
    "print(\"Results for Specialists:\")\n",
    "print(\"Average S-Recall for llm_slateq_slate:\")\n",
    "print(f\"Category Level: {llm_avg_category_specialists:.4f}, Subcategory Level: {llm_avg_subcategory_specialists:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for slateq_slates:\")\n",
    "print(f\"Category Level: {rl_avg_category_specialists:.4f}, Subcategory Level: {rl_avg_subcategory_specialists:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for slateq_reranked:\")\n",
    "print(f\"Category Level: {slate_avg_category_specialists:.4f}, Subcategory Level: {slate_avg_subcategory_specialists:.4f}\")\n",
    "\n",
    "# Print results for generalists\n",
    "print(\"\\nResults for Generalists:\")\n",
    "print(\"Average S-Recall for llm_slateq_slate:\")\n",
    "print(f\"Category Level: {llm_avg_category_generalists:.4f}, Subcategory Level: {llm_avg_subcategory_generalists:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for slateq_slates:\")\n",
    "print(f\"Category Level: {rl_avg_category_generalists:.4f}, Subcategory Level: {rl_avg_subcategory_generalists:.4f}\")\n",
    "\n",
    "print(\"\\nAverage S-Recall for slateq_reranked:\")\n",
    "print(f\"Category Level: {slate_avg_category_generalists:.4f}, Subcategory Level: {slate_avg_subcategory_generalists:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_data_user_history = category_data.merge(\n",
    "    df_slateq,\n",
    "    left_on=['click', 'observed_state'],\n",
    "    right_on=['original_click', 'initial_user_state_tuple'],\n",
    "    how='right'  # Use 'inner' to keep only matching rows\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract titles from the list of tuples\n",
    "def extract_titles(item_tuples):\n",
    "    return [title for (_, title) in item_tuples]\n",
    "\n",
    "# Function to compute BLEU score between two lists of titles\n",
    "def compute_bleu_score(reference, candidate):\n",
    "    reference_tokens = [word_tokenize(str(title)) for title in reference]\n",
    "    candidate_tokens = word_tokenize(str(candidate[0]))  # Ensure candidate is a single tokenized sentence\n",
    "    \n",
    "    # Compute BLEU score\n",
    "    smoothing = SmoothingFunction().method1\n",
    "    return sentence_bleu(reference_tokens, candidate_tokens, smoothing_function=smoothing)\n",
    "# Compute BLEU scores for each row\n",
    "clicked_data_user_history['bleu_rl_vs_presented'] = clicked_data_user_history.apply(\n",
    "    lambda row: compute_bleu_score(\n",
    "        extract_titles(get_item_ids_and_titles(row['presented_slate'], news_df)),\n",
    "        extract_titles(get_item_ids_and_titles(row['slateq_slates'], news_df)),  # Replace None with your news_df# Replace None with your news_df\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "clicked_data_user_history['bleu_llm_vs_presented'] = clicked_data_user_history.apply(\n",
    "    lambda row: compute_bleu_score(\n",
    "        extract_titles(get_item_ids_and_titles(row['presented_slate'], news_df)) ,\n",
    "        extract_titles(get_item_ids_and_titles(row['llm_slateq_slate'], news_df)),  # Replace None with your news_df# Replace None with your news_df\n",
    "    ), axis=1\n",
    ")\n",
    "\n",
    "clicked_data_user_history['bleu_reranked_vs_presented'] = clicked_data_user_history.apply(\n",
    "    lambda row: compute_bleu_score(\n",
    "        extract_titles(get_item_ids_and_titles(row['presented_slate'], news_df)) ,\n",
    "        extract_titles(get_item_ids_and_titles(row['slateq_reranked'], news_df)),  # Replace None with your news_df# Replace None with your news_df\n",
    "    ), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  \\\n",
      "0   (0.13400940597057343, 0.2015896886587143, -0.0...   \n",
      "1   (0.15157544612884521, 0.33397215604782104, -0....   \n",
      "2   (0.15727820992469788, 0.2477571815252304, -0.1...   \n",
      "3   (0.1577419489622116, 0.21108318865299225, -0.0...   \n",
      "4   (0.15791304409503937, 0.29125070571899414, -0....   \n",
      "..                                                ...   \n",
      "95  (0.2903972268104553, 0.15165531635284424, -0.0...   \n",
      "96  (0.2935115098953247, 0.13266007602214813, -0.1...   \n",
      "97  (0.29664674401283264, 0.14605002105236053, 0.0...   \n",
      "98  (0.29784202575683594, 0.2651831805706024, 0.01...   \n",
      "99  (0.2985374331474304, 0.1253967434167862, 0.048...   \n",
      "\n",
      "    group_mean_bleu_rl_vs_presented  \n",
      "0                          0.016792  \n",
      "1                          0.021105  \n",
      "2                          0.500000  \n",
      "3                          1.000000  \n",
      "4                          0.021016  \n",
      "..                              ...  \n",
      "95                         0.289239  \n",
      "96                         1.000000  \n",
      "97                         0.519756  \n",
      "98                         0.018477  \n",
      "99                         0.511115  \n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.3701003809647881\n"
     ]
    }
   ],
   "source": [
    "grouped_means_bleu_rl = clicked_data_user_history.groupby('initial_user_state_tuple')['bleu_rl_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_rl.rename(columns={'bleu_rl_vs_presented': 'group_mean_bleu_rl_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_bleu_rl['group_mean_bleu_rl_vs_presented'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_bleu_rl)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for specialists and generalists\n",
    "specialists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'specialist'].copy()\n",
    "generalists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 1: Group by initial_user_state_tuple and calculate the mean of bleu_rl_vs_presented for specialists\n",
    "grouped_means_bleu_rl_specialists = specialists_data.groupby('initial_user_state_tuple')['bleu_rl_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_rl_specialists.rename(columns={'bleu_rl_vs_presented': 'group_mean_bleu_rl_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of bleu_rl_vs_presented for generalists\n",
    "grouped_means_bleu_rl_generalists = generalists_data.groupby('initial_user_state_tuple')['bleu_rl_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_rl_generalists.rename(columns={'bleu_rl_vs_presented': 'group_mean_bleu_rl_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means for specialists and generalists\n",
    "overall_mean_specialists = grouped_means_bleu_rl_specialists['group_mean_bleu_rl_vs_presented'].mean()\n",
    "overall_mean_generalists = grouped_means_bleu_rl_generalists['group_mean_bleu_rl_vs_presented'].mean()\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  \\\n",
      "0   (0.13400940597057343, 0.2015896886587143, -0.0...   \n",
      "1   (0.15157544612884521, 0.33397215604782104, -0....   \n",
      "2   (0.15727820992469788, 0.2477571815252304, -0.1...   \n",
      "3   (0.1577419489622116, 0.21108318865299225, -0.0...   \n",
      "4   (0.15791304409503937, 0.29125070571899414, -0....   \n",
      "..                                                ...   \n",
      "95  (0.2903972268104553, 0.15165531635284424, -0.0...   \n",
      "96  (0.2935115098953247, 0.13266007602214813, -0.1...   \n",
      "97  (0.29664674401283264, 0.14605002105236053, 0.0...   \n",
      "98  (0.29784202575683594, 0.2651831805706024, 0.01...   \n",
      "99  (0.2985374331474304, 0.1253967434167862, 0.048...   \n",
      "\n",
      "    group_mean_bleu_reranked_vs_presented  \n",
      "0                                0.509399  \n",
      "1                                0.681157  \n",
      "2                                0.025915  \n",
      "3                                0.021359  \n",
      "4                                0.017476  \n",
      "..                                    ...  \n",
      "95                               0.511045  \n",
      "96                               1.000000  \n",
      "97                               0.756944  \n",
      "98                               0.015966  \n",
      "99                               0.682333  \n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.40505892939061766\n"
     ]
    }
   ],
   "source": [
    "grouped_means_bleu_bm25 = clicked_data_user_history.groupby('initial_user_state_tuple')['bleu_reranked_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_bm25.rename(columns={'bleu_reranked_vs_presented': 'group_mean_bleu_reranked_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_bleu_bm25['group_mean_bleu_reranked_vs_presented'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_bleu_bm25)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for specialists and generalists\n",
    "specialists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'specialist'].copy()\n",
    "generalists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 1: Group by initial_user_state_tuple and calculate the mean of bleu_reranked_vs_presented for specialists\n",
    "grouped_means_bleu_reranked_specialists = specialists_data.groupby('initial_user_state_tuple')['bleu_reranked_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_reranked_specialists.rename(columns={'bleu_reranked_vs_presented': 'group_mean_bleu_reranked_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of bleu_reranked_vs_presented for generalists\n",
    "grouped_means_bleu_reranked_generalists = generalists_data.groupby('initial_user_state_tuple')['bleu_reranked_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_reranked_generalists.rename(columns={'bleu_reranked_vs_presented': 'group_mean_bleu_reranked_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means for specialists and generalists\n",
    "overall_mean_specialists = grouped_means_bleu_reranked_specialists['group_mean_bleu_reranked_vs_presented'].mean()\n",
    "overall_mean_generalists = grouped_means_bleu_reranked_generalists['group_mean_bleu_reranked_vs_presented'].mean()\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  \\\n",
      "0   (0.13400940597057343, 0.2015896886587143, -0.0...   \n",
      "1   (0.15157544612884521, 0.33397215604782104, -0....   \n",
      "2   (0.15727820992469788, 0.2477571815252304, -0.1...   \n",
      "3   (0.1577419489622116, 0.21108318865299225, -0.0...   \n",
      "4   (0.15791304409503937, 0.29125070571899414, -0....   \n",
      "..                                                ...   \n",
      "95  (0.2903972268104553, 0.15165531635284424, -0.0...   \n",
      "96  (0.2935115098953247, 0.13266007602214813, -0.1...   \n",
      "97  (0.29664674401283264, 0.14605002105236053, 0.0...   \n",
      "98  (0.29784202575683594, 0.2651831805706024, 0.01...   \n",
      "99  (0.2985374331474304, 0.1253967434167862, 0.048...   \n",
      "\n",
      "    group_mean_bleu_llm_vs_presented  \n",
      "0                           0.022188  \n",
      "1                           0.672187  \n",
      "2                           0.026315  \n",
      "3                           1.000000  \n",
      "4                           0.021973  \n",
      "..                               ...  \n",
      "95                          0.518924  \n",
      "96                          1.000000  \n",
      "97                          1.000000  \n",
      "98                          0.038854  \n",
      "99                          0.198119  \n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.46988566939943555\n"
     ]
    }
   ],
   "source": [
    "grouped_means_bleu_llm = clicked_data_user_history.groupby('initial_user_state_tuple')['bleu_llm_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_llm.rename(columns={'bleu_llm_vs_presented': 'group_mean_bleu_llm_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_bleu_llm['group_mean_bleu_llm_vs_presented'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_bleu_llm)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for specialists and generalists\n",
    "specialists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'specialist'].copy()\n",
    "generalists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 1: Group by initial_user_state_tuple and calculate the mean of bleu_llm_vs_presented for specialists\n",
    "grouped_means_bleu_llm_specialists = specialists_data.groupby('initial_user_state_tuple')['bleu_llm_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_llm_specialists.rename(columns={'bleu_llm_vs_presented': 'group_mean_bleu_llm_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of bleu_llm_vs_presented for generalists\n",
    "grouped_means_bleu_llm_generalists = generalists_data.groupby('initial_user_state_tuple')['bleu_llm_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_llm_generalists.rename(columns={'bleu_llm_vs_presented': 'group_mean_bleu_llm_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means for specialists and generalists\n",
    "overall_mean_specialists = grouped_means_bleu_llm_specialists['group_mean_bleu_llm_vs_presented'].mean()\n",
    "overall_mean_generalists = grouped_means_bleu_llm_generalists['group_mean_bleu_llm_vs_presented'].mean()\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "feather_file_path_llm= gen_slates_dir / \"llm_slates.feather\"\n",
    "df_llm = pd.read_feather(feather_file_path_llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_llm['initial_user_state_tuple'] = df_llm['initial_user_state'].apply(tuple)\n",
    "# Step 2: Merge with df_llm based on the matching condition\n",
    "df_llm = pd.merge(\n",
    "    df_llm,\n",
    "    click_history_data,\n",
    "    left_on='initial_user_state_tuple',\n",
    "    right_on='observed_state',\n",
    "    how='left'  # Use 'left' to keep all rows from df_llm, or 'inner' for only matching rows\n",
    ")\n",
    "\n",
    "# Drop the extra 'observed_state' column if you don't need it\n",
    "df_llm = df_llm.drop(columns=['observed_state'])\n",
    "df_llm['diversity_score']=df_llm.apply(entropy_based_diversity,axis=1)\n",
    "q1 = df_llm['diversity_score'].quantile(0.25)\n",
    "conditions = [\n",
    "    df_llm['diversity_score'] == 0,  # Cold\n",
    "    df_llm['diversity_score'] <= q1,  # Specialist\n",
    "    df_llm['diversity_score'] > q1    # Generalist\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    'cold',\n",
    "    'specialist',\n",
    "    'generalist'\n",
    "]\n",
    "\n",
    "# Step 3: Use numpy.select to apply the conditions\n",
    "df_llm['user_type'] = np.select(conditions, choices, default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  group_mean_hit\n",
      "0   (-0.0259791798889637, 0.5851805210113525, 0.00...        0.500000\n",
      "1   (0.049241334199905396, 0.23491184413433075, 0....        0.333333\n",
      "2   (0.06917192041873932, 0.22154483199119568, 0.0...        0.000000\n",
      "3   (0.0808219462633133, 0.280564546585083, -0.035...        0.142857\n",
      "4   (0.11326862126588821, 0.38108861446380615, -0....        0.285714\n",
      "..                                                ...             ...\n",
      "95  (0.3616601228713989, 0.1373804360628128, 0.021...        0.000000\n",
      "96  (0.3617928624153137, 0.11457429826259613, 0.01...        0.000000\n",
      "97  (0.36578845977783203, 0.042487733066082, 0.081...        0.500000\n",
      "98  (0.39353927969932556, 0.0698390007019043, -0.0...        0.000000\n",
      "99  (0.3967207372188568, 0.18588663637638092, -0.0...        0.000000\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.16706782106782106\n"
     ]
    }
   ],
   "source": [
    "df_llm= df_llm[df_llm['llm_gen_slate'].apply(lambda x: len(x) > 0)].copy()\n",
    "df_llm['initial_user_state_tuple'] = df_llm['initial_user_state'].apply(tuple)\n",
    "\n",
    "# Step 2: Group by initial_user_state and calculate the mean of 'hit' for each group\n",
    "grouped_means_rl_llm = df_llm.groupby('initial_user_state_tuple')['llm_hit'].mean().reset_index()\n",
    "grouped_means_rl_llm.rename(columns={'llm_hit': 'group_mean_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_rl_llm['group_mean_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_rl_llm)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter the DataFrame for specialists and generalists\n",
    "specialists_df = df_llm[df_llm['user_type'] == 'specialist'].copy()\n",
    "generalists_df = df_llm[df_llm['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of 'llm_hit' for each group\n",
    "# For specialists\n",
    "grouped_means_specialists = specialists_df.groupby('initial_user_state_tuple')['llm_hit'].mean().reset_index()\n",
    "grouped_means_specialists.rename(columns={'llm_hit': 'group_mean_slateq_hit'}, inplace=True)\n",
    "\n",
    "# For generalists\n",
    "grouped_means_generalists = generalists_df.groupby('initial_user_state_tuple')['llm_hit'].mean().reset_index()\n",
    "grouped_means_generalists.rename(columns={'llm_hit': 'group_mean_slateq_hit'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "# For specialists\n",
    "overall_mean_specialists = grouped_means_specialists['group_mean_slateq_hit'].mean()\n",
    "\n",
    "# For generalists\n",
    "overall_mean_generalists = grouped_means_generalists['group_mean_slateq_hit'].mean()\n",
    "\n",
    "# Display the results\n",
    "# print(\"Group-level averages for Specialists:\")\n",
    "# print(grouped_means_specialists)\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "# print(\"\\nGroup-level averages for Generalists:\")\n",
    "# print(grouped_means_generalists)\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average S-Recall for llm_slate:\n",
      "Category Level: 0.3645, Subcategory Level: 0.6131\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary for quick lookup of category and subcategory\n",
    "item_to_category = dict(zip(news_df['itemId'], news_df['category']))\n",
    "item_to_subcategory = dict(zip(news_df['itemId'], news_df['subcategory']))\n",
    "\n",
    "# Calculate total unique categories and subcategories in the dataset\n",
    "total_categories = news_df['category'].nunique()\n",
    "total_subcategories = news_df['subcategory'].nunique()\n",
    "\n",
    "# Function to calculate diversity metrics for a given slate\n",
    "def calculate_diversity(slate, item_to_category, item_to_subcategory):\n",
    "    categories = set()\n",
    "    subcategories = set()\n",
    "    \n",
    "    for item in slate:\n",
    "        if item in item_to_category:\n",
    "            categories.add(item_to_category[item])\n",
    "        if item in item_to_subcategory:\n",
    "            subcategories.add(item_to_subcategory[item])\n",
    "    \n",
    "    return len(categories), len(subcategories)\n",
    "\n",
    "# Function to calculate S-Recall as a ratio\n",
    "def calculate_s_recall(df, column, item_to_category, item_to_subcategory, total_categories, total_subcategories):\n",
    "    results = []\n",
    "    \n",
    "    for slate in df[column]:\n",
    "        category_diversity, subcategory_diversity = calculate_diversity(slate, item_to_category, item_to_subcategory)\n",
    "        \n",
    "        # Calculate S-Recall as a ratio\n",
    "        s_recall_category = category_diversity / len(slate)\n",
    "        s_recall_subcategory = subcategory_diversity / len(slate)\n",
    "        \n",
    "        results.append((s_recall_category, s_recall_subcategory))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Calculate S-Recall for each slate column\n",
    "llm_s_recall = calculate_s_recall(df_llm, 'llm_gen_slate', item_to_category, item_to_subcategory, total_categories, total_subcategories)\n",
    "\n",
    "# Calculate average S-Recall for each column\n",
    "def calculate_average_s_recall(s_recall_results):\n",
    "    avg_category = sum([x[0] for x in s_recall_results]) / len(s_recall_results)\n",
    "    avg_subcategory = sum([x[1] for x in s_recall_results]) / len(s_recall_results)\n",
    "    return avg_category, avg_subcategory\n",
    "\n",
    "llm_avg_category, llm_avg_subcategory = calculate_average_s_recall(llm_s_recall)\n",
    "\n",
    "\n",
    "# Print average S-Recall for each column\n",
    "print(\"Average S-Recall for llm_slate:\")\n",
    "print(f\"Category Level: {llm_avg_category:.4f}, Subcategory Level: {llm_avg_subcategory:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average S-Recall for llm_slate:\n",
      "Category Level: 0.3645, Subcategory Level: 0.0676\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a dictionary to map categories to their subcategories\n",
    "category_to_subcategories = news_df.groupby('category')['subcategory'].unique().to_dict()\n",
    "\n",
    "# Function to calculate diversity metrics for a given slate\n",
    "def calculate_diversity(slate, item_to_category, item_to_subcategory):\n",
    "    categories = set()\n",
    "    subcategories = set()\n",
    "    \n",
    "    for item in slate:\n",
    "        if item in item_to_category:\n",
    "            categories.add(item_to_category[item])\n",
    "        if item in item_to_subcategory:\n",
    "            subcategories.add(item_to_subcategory[item])\n",
    "    \n",
    "    return categories, subcategories\n",
    "\n",
    "# Function to calculate S-Recall as a ratio\n",
    "def calculate_s_recall(df, column, item_to_category, item_to_subcategory, category_to_subcategories):\n",
    "    results = []\n",
    "    \n",
    "    for slate in df[column]:\n",
    "        categories_in_slate, subcategories_in_slate = calculate_diversity(slate, item_to_category, item_to_subcategory)\n",
    "        \n",
    "        # Calculate S-Recall at category level\n",
    "        s_recall_category = len(categories_in_slate) / len(slate)\n",
    "        \n",
    "        # Calculate S-Recall at subcategory level (contextual to categories in the slate)\n",
    "        total_subcategories_in_categories = set()\n",
    "        for category in categories_in_slate:\n",
    "            total_subcategories_in_categories.update(category_to_subcategories[category])\n",
    "        \n",
    "        s_recall_subcategory = len(subcategories_in_slate) / len(total_subcategories_in_categories)\n",
    "        \n",
    "        results.append((s_recall_category, s_recall_subcategory))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Calculate S-Recall for each slate column\n",
    "llm_s_recall = calculate_s_recall(df_llm, 'llm_gen_slate', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "\n",
    "# Calculate average S-Recall for each column\n",
    "def calculate_average_s_recall(s_recall_results):\n",
    "    avg_category = sum([x[0] for x in s_recall_results]) / len(s_recall_results)\n",
    "    avg_subcategory = sum([x[1] for x in s_recall_results]) / len(s_recall_results)\n",
    "    return avg_category, avg_subcategory\n",
    "\n",
    "llm_avg_category, llm_avg_subcategory = calculate_average_s_recall(llm_s_recall)\n",
    "\n",
    "\n",
    "# Print average S-Recall for each column\n",
    "print(\"Average S-Recall for llm_slate:\")\n",
    "print(f\"Category Level: {llm_avg_category:.4f}, Subcategory Level: {llm_avg_subcategory:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for specialists and generalists\n",
    "specialists_df = df_llm[df_llm['user_type'] == 'specialist'].copy()\n",
    "generalists_df = df_llm[df_llm['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Function to calculate S-Recall for a given DataFrame\n",
    "def calculate_s_recall_for_df(df_llm, column, item_to_category, item_to_subcategory, category_to_subcategories):\n",
    "    results = []\n",
    "    \n",
    "    for slate in df_llm[column]:\n",
    "        categories_in_slate, subcategories_in_slate = calculate_diversity(slate, item_to_category, item_to_subcategory)\n",
    "        \n",
    "        # Calculate S-Recall at category level\n",
    "        s_recall_category = len(categories_in_slate) / len(slate)\n",
    "        \n",
    "        # Calculate S-Recall at subcategory level (contextual to categories in the slate)\n",
    "        total_subcategories_in_categories = set()\n",
    "        for category in categories_in_slate:\n",
    "            total_subcategories_in_categories.update(category_to_subcategories[category])\n",
    "        \n",
    "        s_recall_subcategory = len(subcategories_in_slate) / len(total_subcategories_in_categories)\n",
    "        \n",
    "        results.append((s_recall_category, s_recall_subcategory))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Calculate S-Recall for specialists\n",
    "llm_s_recall_specialists = calculate_s_recall_for_df(specialists_df, 'llm_gen_slate', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "\n",
    "\n",
    "# Calculate S-Recall for generalists\n",
    "llm_s_recall_generalists = calculate_s_recall_for_df(generalists_df, 'llm_gen_slate', item_to_category, item_to_subcategory, category_to_subcategories)\n",
    "\n",
    "\n",
    "# Function to calculate average S-Recall\n",
    "def calculate_average_s_recall(s_recall_results):\n",
    "    avg_category = sum([x[0] for x in s_recall_results]) / len(s_recall_results)\n",
    "    avg_subcategory = sum([x[1] for x in s_recall_results]) / len(s_recall_results)\n",
    "    return avg_category, avg_subcategory\n",
    "\n",
    "# Calculate average S-Recall for specialists\n",
    "llm_avg_category_specialists, llm_avg_subcategory_specialists = calculate_average_s_recall(llm_s_recall_specialists)\n",
    "\n",
    "\n",
    "# Calculate average S-Recall for generalists\n",
    "llm_avg_category_generalists, llm_avg_subcategory_generalists = calculate_average_s_recall(llm_s_recall_generalists)\n",
    "\n",
    "# Print results for specialists\n",
    "print(\"Results for Specialists:\")\n",
    "print(\"Average S-Recall for llm_slate:\")\n",
    "print(f\"Category Level: {llm_avg_category_specialists:.4f}, Subcategory Level: {llm_avg_subcategory_specialists:.4f}\")\n",
    "\n",
    "\n",
    "# Print results for generalists\n",
    "print(\"\\nResults for Generalists:\")\n",
    "print(\"Average S-Recall for llm_slate:\")\n",
    "print(f\"Category Level: {llm_avg_category_generalists:.4f}, Subcategory Level: {llm_avg_subcategory_generalists:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "clicked_data_user_history = category_data.merge(\n",
    "    df_llm,\n",
    "    left_on=['click', 'observed_state'],\n",
    "    right_on=['original_click', 'initial_user_state_tuple'],\n",
    "    how='right'  # Use 'inner' to keep only matching rows\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract titles from the list of tuples\n",
    "def extract_titles(item_tuples):\n",
    "    return [title for (_, title) in item_tuples]\n",
    "\n",
    "# Function to compute BLEU score between two lists of titles\n",
    "def compute_bleu_score(reference, candidate):\n",
    "    reference_tokens = [word_tokenize(str(title)) for title in reference]\n",
    "    candidate_tokens = word_tokenize(str(candidate[0]))  # Ensure candidate is a single tokenized sentence\n",
    "    \n",
    "    # Compute BLEU score\n",
    "    smoothing = SmoothingFunction().method1\n",
    "    return sentence_bleu(reference_tokens, candidate_tokens, smoothing_function=smoothing)\n",
    "\n",
    "\n",
    "clicked_data_user_history['bleu_llm_vs_presented'] = clicked_data_user_history.apply(\n",
    "    lambda row: compute_bleu_score(\n",
    "        extract_titles(get_item_ids_and_titles(row['presented_slate'], news_df)) ,\n",
    "        extract_titles(get_item_ids_and_titles(row['llm_gen_slate'], news_df)),  # Replace None with your news_df# Replace None with your news_df\n",
    "    ), axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group-level averages:\n",
      "                             initial_user_state_tuple  \\\n",
      "0   (-0.0259791798889637, 0.5851805210113525, 0.00...   \n",
      "1   (0.049241334199905396, 0.23491184413433075, 0....   \n",
      "2   (0.06917192041873932, 0.22154483199119568, 0.0...   \n",
      "3   (0.0808219462633133, 0.280564546585083, -0.035...   \n",
      "4   (0.11326862126588821, 0.38108861446380615, -0....   \n",
      "..                                                ...   \n",
      "95  (0.3616601228713989, 0.1373804360628128, 0.021...   \n",
      "96  (0.3617928624153137, 0.11457429826259613, 0.01...   \n",
      "97  (0.36578845977783203, 0.042487733066082, 0.081...   \n",
      "98  (0.39353927969932556, 0.0698390007019043, -0.0...   \n",
      "99  (0.3967207372188568, 0.18588663637638092, -0.0...   \n",
      "\n",
      "    group_mean_bleu_llm_vs_presented  \n",
      "0                           1.000000  \n",
      "1                           0.021973  \n",
      "2                           0.018409  \n",
      "3                           0.041316  \n",
      "4                           0.585378  \n",
      "..                               ...  \n",
      "95                          0.018477  \n",
      "96                          0.043242  \n",
      "97                          0.213435  \n",
      "98                          0.029069  \n",
      "99                          1.000000  \n",
      "\n",
      "[100 rows x 2 columns]\n",
      "\n",
      "Overall average:\n",
      "0.47951284871133226\n"
     ]
    }
   ],
   "source": [
    "grouped_means_bleu_llm = clicked_data_user_history.groupby('initial_user_state_tuple')['bleu_llm_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_llm.rename(columns={'bleu_llm_vs_presented': 'group_mean_bleu_llm_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means\n",
    "overall_mean = grouped_means_bleu_llm['group_mean_bleu_llm_vs_presented'].mean()\n",
    "\n",
    "# Display the results\n",
    "print(\"Group-level averages:\")\n",
    "print(grouped_means_bleu_llm)\n",
    "print(\"\\nOverall average:\")\n",
    "print(overall_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for specialists and generalists\n",
    "specialists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'specialist'].copy()\n",
    "generalists_data = clicked_data_user_history[clicked_data_user_history['user_type'] == 'generalist'].copy()\n",
    "\n",
    "# Step 1: Group by initial_user_state_tuple and calculate the mean of bleu_llm_vs_presented for specialists\n",
    "grouped_means_bleu_llm_specialists = specialists_data.groupby('initial_user_state_tuple')['bleu_llm_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_llm_specialists.rename(columns={'bleu_llm_vs_presented': 'group_mean_bleu_llm_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 2: Group by initial_user_state_tuple and calculate the mean of bleu_llm_vs_presented for generalists\n",
    "grouped_means_bleu_llm_generalists = generalists_data.groupby('initial_user_state_tuple')['bleu_llm_vs_presented'].mean().reset_index()\n",
    "grouped_means_bleu_llm_generalists.rename(columns={'bleu_llm_vs_presented': 'group_mean_bleu_llm_vs_presented'}, inplace=True)\n",
    "\n",
    "# Step 3: Calculate the overall average of the group means for specialists and generalists\n",
    "overall_mean_specialists = grouped_means_bleu_llm_specialists['group_mean_bleu_llm_vs_presented'].mean()\n",
    "overall_mean_generalists = grouped_means_bleu_llm_generalists['group_mean_bleu_llm_vs_presented'].mean()\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Specialists:\")\n",
    "print(overall_mean_specialists)\n",
    "\n",
    "\n",
    "print(\"\\nOverall average for Generalists:\")\n",
    "print(overall_mean_generalists)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
